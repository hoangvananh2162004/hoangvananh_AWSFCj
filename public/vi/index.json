[
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Hoàng Văn Anh\nSố điện thoại: 0375956650\nEmail: anhhvse180142@fpt.edu.vn\nMã Số Sinh Viên: SE180142\nTrường: Đại học FPT Hồ Chí Minh\nNgành: Trí Tuệ Nhân Tạo\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 09/09/2025 đến ngày 09/02/2026\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Mở rộng deployment pipeline với Amazon ECS blue/green deployments và lifecycle hooks. Bởi Olly Pomeroy | vào ngày 11 THÁNG 9, 2025 | trong Amazon Elastic Container Service, Containers | Permalink\nChiến lược blue/green deployment cho phép bạn release ứng dụng bằng cách chuyển hướng traffic giữa hai môi trường giống hệt nhau đang chạy các phiên bản khác nhau của ứng dụng. Điều này giúp bạn giảm thiểu các rủi ro thường gặp khi deploy phần mềm, bởi vì bạn có thể rollback về một deployment trước đó ngay lập tức. Amazon Elastic Container Service (Amazon ECS) gần đây đã công bố hỗ trợ native cho blue/green deployments, loại bỏ nhu cầu quản lý và tích hợp với các công cụ deployment khác. Như một phần của lần phát hành này, Amazon ECS cũng đã giới thiệu lifecycle hooks cho deployments. Lifecycle hooks cho phép bạn tích hợp test suites, manual approvals, và metrics vào deployment pipeline của mình. Trong bài viết này, chúng tôi sẽ đi sâu vào lifecycle hooks và chỉ ra cách chúng có thể được tích hợp vào deployment workflows.\nBối Cảnh Khi một Amazon ECS service được tạo hoặc cập nhật, chúng tôi sẽ tạo ra một immutable object chứa chính xác specification của nó, được gọi là một Amazon ECS service revision. Sau đó, control plane sẽ cố gắng deploy service revision này thông qua một Amazon ECS service deployment. Một deployment sẽ trải qua multiple lifecycle states, chẳng hạn như IN_PROGRESS và SUCCESSFUL. Trong lần phát hành blue/green gần đây, có một subcategory mới nằm bên dưới các states này, được gọi là lifecycle stages. Khi một deployment bắt đầu, chúng tôi sẽ xử lý tuần tự qua từng lifecycle stage, với tùy chọn mở rộng deployment bằng custom logic được đóng gói trong lifecycle hooks. Hình minh họa sau đây cho thấy mối quan hệ giữa lifecycle states, lifecycle stages, và lifecycle hooks.\nLifecycle hooks là các synchronous AWS Lambda functions mà Amazon ECS control plane sẽ invoke thay cho bạn. Bạn có thể viết bất kỳ logic nào bạn muốn trong các function này bằng bất kỳ runtime language nào bạn chọn. Khi function đã thực thi xong logic của nó, nó phải return một hookStatus để Amazon ECS deployment có thể tiếp tục. Nếu hookStatus không được return, hoặc nếu function bị lỗi, thì Amazon ECS deployment sẽ rollback.\nCác giá trị của hookStatus có thể là:\nSUCCEEDED: deployment tiếp tục sang lifecycle stage tiếp theo. FAILED: deployment sẽ rollback về deployment cuối cùng đã thành công. IN_PROGRESS: Amazon ECS control plane sẽ invoke lại function sau một khoảng thời gian ngắn. Mặc định là 30 giây, nhưng có thể điều chỉnh bằng cách return một callBackDelay. IN_PROGRESS hook status IN_PROGRESS status cung cấp một cơ chế mạnh mẽ và linh hoạt để giám sát và kiểm soát Amazon ECS deployment. Function này là một synchronous event, do đó deployment chỉ có thể tạm dừng trong thời gian thực thi tối đa của một function (15 phút). Có thể có những tình huống bạn cần thực thi complex logic hoặc tạm dừng để chờ thêm dữ liệu, chẳng hạn như chờ một full test suite chạy trên test endpoint. Phản hồi hookStatus này cho phép bạn đạt được điều đó. Khi IN_PROGRESS hook status được return, Amazon ECS control plane sẽ invoke lại function sau 30 giây (hoặc khoảng thời gian được return trong key callBackDelay). Amazon ECS sẽ tiếp tục invoke function cho đến khi một SUCCEEDED hoặc FAILED hook status được return; do đó cho phép thực thi validation logic cần nhiều thời gian hơn so với thời gian thực thi của một function duy nhất.\nTruyền trạng thái với hookDetails Lifecycle hooks thường được định nghĩa một lần và tái sử dụng trên nhiều ECS services trong một tổ chức. Để làm cho lifecycle hooks độc lập với ECS service, bạn có thể sử dụng hookDetails dictionary để truyền vào dữ liệu cụ thể của service khi tạo hoặc cập nhật một service. Dưới đây là một trích đoạn từ một ECS service nơi chúng tôi đã định nghĩa một lifecycle hook và truyền vào một Amazon S3 Bucket.\n{ \u0026#34;hookTargetArn\u0026#34;: \u0026#34;arn:aws:lambda:\u0026lt;region\u0026gt;:\u0026lt;account_id\u0026gt;:function:\u0026lt;function_name\u0026gt;\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;account_id\u0026gt;:role/\u0026lt;iam_role_name\u0026gt;\u0026#34;, \u0026#34;lifecycleStages\u0026#34;: [\u0026#34;POST_TEST_TRAFFIC_SHIFT\u0026#34;], \u0026#34;hookDetails\u0026#34;: { \u0026#34;S3_BUCKET_NAME\u0026#34;: \u0026#34;mys3bucket\u0026#34; }, } Ngoài ra, bạn cũng có thể sử dụng hookDetails dictionary để truyền state giữa các lần invocation của cùng một lifecycle hook. Nếu một hook return IN_PROGRESS status, bạn cũng có thể bao gồm hookDetails dictionary với nhiều cặp key/value, loại bỏ nhu cầu phải lưu state ở nơi khác. Các trường hợp sử dụng phổ biến bao gồm truyền metric counters hoặc Amazon Resource Names (ARNs) của các external resources giữa các lần invocation. Lưu ý rằng dữ liệu được thêm vào hookDetails theo cách này chỉ tồn tại giữa các lần invocation của cùng một hook trong một deployment. Dữ liệu sẽ không được mang sang giữa các hook khác nhau trong cùng một deployment, hoặc cùng một hook ở các deployment khác nhau.\n{ \u0026#34;hookStatus\u0026#34;: \u0026#34; IN_PROGRESS\u0026#34;, \u0026#34;callBackDelay\u0026#34;: 90, \u0026#34;hookDetails\u0026#34;: { \u0026#34;SFN_EXECUTION_ARN\u0026#34;: \u0026#34;arn:aws:states:\u0026lt;region\u0026gt;:\u0026lt;account_id\u0026gt;:execution:\u0026lt;sfn\u0026gt;:\u0026lt;id\u0026gt;\u0026#34;, }, } PRE_SCALE_UP hook PRE_SCALE_UP lifecycle hook là duy nhất trong Amazon ECS deployments vì nó là hook duy nhất có sẵn cho cả blue green deployment strategy mới cũng như rolling update strategy hiện tại. PRE_SCALE_UP hook chạy trước khi các new tasks được tạo, cho phép bạn áp dụng admission logic trong Amazon ECS. Một cách sử dụng phổ biến của hook này là đánh giá Amazon ECS task definition dựa trên governance policy trước khi các tasks được scheduled. Trước đây, nếu bạn muốn áp dụng một policy cho các tasks, bạn chỉ có thể phản hồi khi task đã được scheduled. Một ví dụ về mô hình trước đó có thể được tìm thấy trong GitHub repository. Mô hình trước đây có những hạn chế khi các tasks không an toàn hoặc có lỗ hổng có thể đang chạy trước khi policy của bạn phát hiện ra vi phạm. Hook mới này cho phép các trường hợp sử dụng như xác minh container image signature hoặc container image repository trước khi workload được scheduled.\nWalkthrough Trong walkthrough này, chúng tôi sẽ trình bày các patterns khác nhau để minh họa sức mạnh của lifecycle hooks. Trước tiên, chúng tôi sẽ trình diễn cách một PRE_SCALE_UP hook có thể được sử dụng như một dạng admission hook, tiếp theo, chúng tôi sẽ chỉ ra cách một POST_TEST_TRAFFIC_SHIFT hook có thể được sử dụng để áp dụng bước manual approval trước khi production traffic được chuyển đổi.\nĐiều kiện tiên quyết Để triển khai walkthrough này, bạn cần quyền truy cập vào một AWS account với một workstation đã cài đặt AWS Command Line Interface (AWS CLI), AWS Cloud Development Kit (AWS CDK), và Docker Engine.\nTrong suốt walkthrough này, chúng tôi sẽ deploy các resources lên một Amazon ECS cluster và vào một Amazon Virtual Private Cloud (Amazon VPC). Code cho walkthrough này có thể được tìm thấy trong một AWS CDK app trong sample GitHub repository của chúng tôi.\nClone GitHub Repository về máy $ git clone https://github.com/aws-samples/sample-amazon-ecs-blue-green-deployment-patterns.git Triển khai AWS CDK app. AWS CDK app này chứa ba AWS CloudFormation stacks riêng biệt. Nó tạo một Amazon VPC và Application Load Balancer (ALB) trong stack đầu tiên. Trong stack thứ hai, nó tạo một ECS cluster và các AWS Identity and Access Management (IAM) roles cần thiết. Thứ ba, nó tạo một stack chứa các functions của chúng ta. $ cd sample-amazon-ecs-blue-green-deployment-patterns/ecs-bluegreen-lifecycle-hooks $ npm install $ npm run build $ npx cdk deploy --all You can verify that the resources were created correctly with the following:\n$ aws cloudformation list-stacks \\ --query \u0026#34;StackSummaries[?starts_with(StackName, \u0026#39;Ecs\u0026#39;)].[StackName, StackStatus]\u0026#34; \\ --output table Trong kho lưu trữ này, chúng tôi có một template task definition và một service definition. Chúng tôi đã tạo một populate templates bash script trong repository để điền các template này với các giá trị phù hợp với môi trường của bạn. $ ./populate_templates.sh Admission hook demonstration Để minh họa cách một PRE_SCALE_UP hook có thể được sử dụng như một admission hook, chúng tôi sẽ khởi chạy một Amazon ECS service sử dụng container image từ một Amazon Elastic Container Registry (Amazon ECR) public repository. Trong tình huống của chúng tôi, chúng tôi đã viết một policy trong function để đảm bảo rằng tất cả container images đều đến từ một private hoặc public Amazon ECR repository. Chúng tôi có thể thấy policy này được thực thi trong logs của lifecycle hook.\nĐầu tiên, chúng ta xem xét các resources mà chúng ta dự định deploy: Bên trong service definition của chúng ta, bạn sẽ thấy một PRE_SCALE_UP lifecycle hook. $ cat outputs/service.json | jq -r \u0026#39;.deploymentConfiguration.lifecycleHooks[0]\u0026#39; { \u0026#34;hookTargetArn\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:111222333444:function:EcsBluegreenHookStack-admissionFunction1D626CB0-FepCuhdYPhNn\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::111222333444:role/EcsBluegreenEcsStack-ECSLambdaInvokeRole2A82A552-yEE1nb8PewjH\u0026#34;, \u0026#34;lifecycleStages\u0026#34;: [ \u0026#34;PRE_SCALE_UP\u0026#34; ] } Function cho hook này xác minh container image của chúng ta bằng cách sử dụng một regex expression. Bạn có thể xem đoạn code này trên máy local bằng cách in source code ra.\n$ grep -A 20 \u0026#34;def validate_container_images\u0026#34; src/admissionFunction/app.py def validate_container_images(container_image_list): # Regex patterns to match Amazon ECR repository URLs # Format for private ECR: [account-id].dkr.ecr.[region].amazonaws.com/[repository-name]:[tag] # Format for public ECR: public.ecr.aws/aws-containers/[repository-name]:[tag] private_ecr_pattern = r\u0026#34;^(\\d+)\\.dkr\\.ecr\\.([a-z0-9-]+)\\.amazonaws\\.com/.*\u0026#34; public_ecr_pattern = r\u0026#34;^public\\.ecr\\.aws/aws-containers/.*\u0026#34; valid_images = True for container_image in container_image_list:# image_url = container_image[\u0026#34;image\u0026#34;] logger.info(f\u0026#34;Validating image: {image_url}\u0026#34;) if re.match(private_ecr_pattern, image_url) or re.match( public_ecr_pattern, image_url ): logger.info(f\u0026#34;Image {image_url} is from an Amazon ECR repository\u0026#34;) else: logger.warning(f\u0026#34;Image {image_url} is NOT from an Amazon ECR repository\u0026#34;) valid_images = False return valid_images Cuối cùng, bạn có thể thấy container image mà chúng ta đang cố gắng deploy trong task definition của mình.\n$ cat outputs/taskdef.json | jq -r \u0026#39;.containerDefinitions[0].image\u0026#39; public.ecr.aws/aws-containers/retail-store-sample-ui:1.1.0 Chúng tôi tạo Amazon ECS service và quan sát lifecycle hook hoạt động. aws ecs \\ register-task-definition \\ --cli-input-json file://outputs/taskdef.json aws ecs \\ create-service \\ --cli-input-json file://outputs/service.json Trong Amazon ECS console, bạn có thể theo dõi deployment này. Current Deployment stage trong Deployment Tab cho chúng ta biết deployment đang ở lifecycle stage nào. Hãy nhớ rằng lifecycle hook đầu tiên của chúng ta chạy ở PRE_SCALE_UP stage. Bạn có thể xác minh rằng lifecycle hook đã thực thi thành công bằng cách truy cập Amazon CloudWatch Logs console và chọn Log Group có tên bắt đầu bằng /aws/lambda/EcsBlugreenHookStack-admissionFunction. Thành công! Container images được sử dụng trong task definition của chúng ta đã được xác minh theo policy trước khi task được scheduled.\nManual approval demonstration Phần thứ hai của walkthrough tập trung vào bước manual approval ở POST_TEST_TRAFFIC_SHIFT stage. Đây là một stage quan trọng trong deployment pipeline, vì nó diễn ra sau khi test traffic endpoint đã được chuyển sang các green tasks của chúng ta (cho phép bạn chạy test suite), nhưng trước khi production traffic endpoint được di chuyển. Trong walkthrough này, chúng tôi thực hiện một bước manual approval trước khi di chuyển production traffic. Có nhiều cách để thực hiện bước manual approval, nhưng trong minh họa này, chúng tôi sử dụng một file và một Amazon S3 bucket. Function trong lifecycle hook của chúng tôi sẽ cố gắng tìm một file trong S3 bucket có tên trùng với Amazon ECS service revision. Nếu file tồn tại, deployment pipeline sẽ tiếp tục. Nếu file không tồn tại, hook sẽ return trạng thái IN_PROGRESS và chúng tôi sẽ thử lại sau 30 giây.\nĐầu tiên, chúng ta xem xét các resources mà chúng ta dự định deploy. Bên trong service definition của chúng ta, bạn sẽ thấy một POST_TEST_TRAFFIC_SHIFT lifecycle hook. $ cat outputs/service.json | jq -r \u0026#39;.deploymentConfiguration.lifecycleHooks[1]\u0026#39; { \u0026#34;hookTargetArn\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:111222333444:function:EcsBluegreenHookStack-approvalFunctionC7093965-J3YoEQtxR679\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::111222333444:role/EcsBluegreenEcsStack-ECSLambdaInvokeRole2A82A552-9OcKcmXkLe9c\u0026#34;, \u0026#34;lifecycleStages\u0026#34;: [ \u0026#34;POST_TEST_TRAFFIC_SHIFT\u0026#34; ] } Xem source code của function trên máy local cho phép chúng ta kiểm tra logic để tìm file Amazon S3. Chúng tôi đang sử dụng boto3client để cố gắng tìm head object của một file có tên trùng với Amazon ECS service revision ID của chúng ta.\n$ grep -A 20 \u0026#34;def check_s3_file\u0026#34; src/approvalFunction/app.py def check_s3_file(s3_bucket, revision_arn): # Extract the revision from the ARN (everything after the last \u0026#39;/\u0026#39;) revision = revision_arn.split(\u0026#34;/\u0026#34;)[-1] file_name = f\u0026#34;{revision}.txt\u0026#34; logger.info(f\u0026#34;Checking if file {file_name} exists in bucket {s3_bucket}\u0026#34;) # Create S3 client s3_client = boto3.client(\u0026#34;s3\u0026#34;) try: # Use head_object to check if the file exists s3_client.head_object(Bucket=s3_bucket, Key=file_name) logger.info(f\u0026#34;File {file_name} exists in bucket {s3_bucket}\u0026#34;) return True except ClientError as e: if e.response[\u0026#34;Error\u0026#34;][\u0026#34;Code\u0026#34;] == \u0026#34;404\u0026#34;: # The file does not exist logger.info(f\u0026#34;File {file_name} does not exist in bucket {s3_bucket}\u0026#34;) return False Để kích hoạt một deployment, chúng ta cập nhật Amazon ECS service với một force action. Điều này buộc Amazon ECS tạo một service revision mới và redeploy tất cả các tasks, ngay cả khi service specification không thay đổi. export CLUSTER_NAME=$(cat outputs/service.json | jq -r \u0026#39;.cluster\u0026#39;) export SERVICE_NAME=$(cat outputs/service.json | jq -r \u0026#39;.serviceName\u0026#39;) aws ecs \\ update-service \\ --service $SERVICE_NAME \\ --cluster $CLUSTER_NAME \\ --force Bạn có thể theo dõi deployment đang diễn ra trong Amazon ECS console, quan sát service di chuyển qua các lifecycle stages khác nhau. Khi deployment đạt đến POST_TEST_TRAFFIC_SHIFT stage, chúng ta có thể kiểm tra tiến trình của hook. CloudWatch Logs console cung cấp cho chúng ta cái nhìn về những gì đang diễn ra ở stage này. Trong một log group có tên bắt đầu bằng /aws/lambda/EcsBlugreenHookStack-approvalFunction, chúng ta sẽ thấy các invocation của function mỗi 30 giây, cố gắng truy xuất file từ Amazon S3. Để cho phép deployment pipeline tiếp tục, chúng ta tải một file lên S3 bucket. Trước tiên, chúng ta cần lấy Amazon ECS service revision ARN, rút gọn chỉ còn service revision ID, và sử dụng nó làm tên file. export S3_BUCKET_NAME=$(aws cloudformation describe-stacks \\ --stack-name EcsBluegreenHookStack \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApprovalBucketName`].OutputValue\u0026#39; \\ --output text) export ECS_SERVICE_REVISION=$(aws ecs \\ list-service-deployments \\ --service $SERVICE_NAME \\ --cluster $CLUSTER_NAME \\ --query \u0026#39;serviceDeployments[?status==`IN_PROGRESS`].targetServiceRevisionArn\u0026#39; \\ --output text) SERVICE_REVISION_ID=$(echo \u0026#34;$ECS_SERVICE_REVISION\u0026#34; | awk -F/ \u0026#39;{print $NF}\u0026#39;) touch $SERVICE_REVISION_ID.txt aws s3 cp $SERVICE_REVISION_ID.txt s3://$S3_BUCKET_NAME/$SERVICE_REVISION_ID.txt Bây giờ khi file đã tồn tại trong Amazon S3, chúng ta có thể quay lại Amazon ECS console và quan sát deployment hoàn tất. Dọn dẹp Để dọn dẹp các AWS resources đã sử dụng trong suốt walkthrough này, chúng ta phải xóa Amazon ECS service.\n$ aws ecs \\ delete-service \\ --service $SERVICE_NAME \\ --cluster $CLUSTER_NAME \\ --force Tiếp theo, chúng ta xóa các CloudFormation stacks bằng AWS CDK.\n$ cdk destroy --all Kết luận Lifecycle hooks trong Amazon ECS cung cấp vô vàn khả năng để tùy chỉnh deployment pipeline của bạn. Trong bài viết này, chúng tôi đã đề cập đến một vài trường hợp sử dụng phổ biến của các hook này, chẳng hạn như đánh giá một deployment theo governance policies, cũng như thực hiện một bước manual approval. Để tìm hiểu thêm, hãy truy cập Amazon ECS lifecycle hooks documentation và xem các minh họa trên kênh Containers from the Couch trên YouTube.\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Tăng tốc việc kiểm thử serverless với tích hợp LocalStack trong VS Code IDE. Bởi Micah Walter | vào ngày 11 THÁNG 9, 2025 | trong Announcements, AWS Lambda, AWS Serverless Application Model, Developer Tools, Launch, News, Serverless | Permalink | Bình luận\nHôm nay, chúng tôi công bố việc tích hợp LocalStack trong AWS Toolkit for Visual Studio Code, giúp các developer dễ dàng hơn bao giờ hết trong việc test và debug ứng dụng serverless ngay trên môi trường local. Nâng cấp này được xây dựng dựa trên những cải tiến gần đây của chúng tôi đối với trải nghiệm phát triển AWS Lambda, bao gồm console to IDE integration and remote debugging được ra mắt vào tháng 7 năm 2025, tiếp tục cam kết của chúng tôi trong việc đơn giản hóa quá trình phát triển serverless trên Amazon Web Services (AWS).\nKhi xây dựng ứng dụng serverless, các developer thường tập trung vào ba khía cạnh chính để tối ưu trải nghiệm testing: unit testing, integration testing, và debugging các tài nguyên đang chạy trên cloud. Mặc dù AWS Serverless Application Model Command Line Interface (AWS SAM CLI) cung cấp khả năng local unit testing rất tốt cho từng hàm Lambda riêng lẻ, nhưng các developer làm việc với event-driven architectures liên quan đến nhiều dịch vụ AWS như Amazon Simple Queue Service (Amazon SQS), Amazon EventBridge, và Amazon DynamoDB sẽ cần một giải pháp toàn diện hơn cho local integration testing. Mặc dù LocalStack cung cấp khả năng giả lập (emulation) các dịch vụ AWS trên local, developer phải quản lý nó như một công cụ standalone, đòi hỏi cấu hình phức tạp và thường xuyên phải chuyển đổi ngữ cảnh giữa nhiều giao diện khác nhau, làm chậm lại vòng đời phát triển.\nTích hợp LocalStack trong AWS Toolkit cho VS Code Để giải quyết những thách thức này, chúng tôi giới thiệu LocalStack integration để các developer có thể kết nối AWS Toolkit for VS Code trực tiếp với các endpoint của LocalStack. Với tích hợp này, developer có thể test và debug serverless applications mà không cần phải chuyển đổi qua lại giữa các công cụ hay quản lý các thiết lập LocalStack phức tạp. Developer có thể mô phỏng toàn bộ workflow event-driven end-to-end bao gồm các dịch vụ như Lambda, Amazon SQS, và EventBridge ngay tại môi trường local, mà không cần phải quản lý nhiều công cụ, thực hiện các cấu hình endpoint phức tạp, hoặc gặp phải các vấn đề về service boundary vốn trước đây đòi hỏi phải kết nối trực tiếp với cloud resources.\nLợi ích chính của tích hợp này là AWS Toolkit for VS Code giờ đây có thể kết nối đến custom endpoints như LocalStack, điều mà trước đây không thể thực hiện được. Trước đây, để trỏ AWS Toolkit for VS Code đến môi trường LocalStack, developer phải thực hiện cấu hình thủ công và liên tục chuyển đổi ngữ cảnh giữa các công cụ.\nBắt đầu với LocalStack trong VS Code rất đơn giản. Developer có thể bắt đầu với LocalStack Free version, phiên bản cung cấp local emulation cho các dịch vụ AWS cốt lõi, lý tưởng cho giai đoạn phát triển và testing ban đầu. Sử dụng guided application walkthrough trong VS Code, developer có thể cài đặt LocalStack trực tiếp từ giao diện của toolkit, thao tác này sẽ tự động cài đặt extension LocalStack và hướng dẫn họ trong suốt quá trình setup. Khi đã được cấu hình, developer có thể deploy các serverless applications trực tiếp vào môi trường emulated và test functions của họ tại local, tất cả mà không cần rời khỏi IDE.\nHãy thử nghiệm Đầu tiên, tôi sẽ cập nhật bản AWS Toolkit for VS Code của mình lên phiên bản mới nhất. Sau khi làm điều này, tôi có thể thấy một tùy chọn mới khi vào Application Builder và nhấp vào Walkthrough of Application Builder. Tùy chọn này cho phép tôi cài đặt LocalStack chỉ với một lần nhấp.\nSau khi tôi hoàn tất quá trình setup cho LocalStack, tôi có thể khởi chạy nó từ status bar và sau đó chọn LocalStack từ danh sách các configured AWS profiles. Trong ví dụ minh họa này, tôi đang sử dụng Application Composer để xây dựng một serverless architecture đơn giản với Amazon API Gateway, Lambda, và DynamoDB. Thông thường, tôi sẽ deploy nó lên AWS bằng cách sử dụng AWS SAM. Trong trường hợp này, tôi sẽ dùng cùng một lệnh AWS SAM để deploy stack của mình trong môi trường local.\nTôi chỉ cần chạy lệnh sam deploy –guided –profile localstack từ command line và làm theo các bước hướng dẫn như bình thường. Deploying lên LocalStack bằng AWS SAM CLI mang lại trải nghiệm hoàn toàn giống với khi tôi deploy lên AWS. Trong ảnh chụp màn hình bên dưới, tôi có thể thấy standard output từ AWS SAM, cũng như các tài nguyên LocalStack mới của tôi được liệt kê trong AWS Toolkit Explorer.\nTôi thậm chí có thể truy cập vào một Lambda function và chỉnh sửa function code mà tôi đã deploy cục bộ!\nTrên trang web LocalStack, tôi có thể đăng nhập và xem tất cả các resources mà tôi đang chạy cục bộ. Trong ảnh chụp màn hình bên dưới, bạn có thể thấy DynamoDB table cục bộ mà tôi vừa deploy.\nQuy trình phát triển được nâng cao Những khả năng mới này bổ sung cho các tính năng console-to-IDE integration và remote debugging mà chúng tôi vừa ra mắt gần đây, tạo nên một trải nghiệm phát triển toàn diện đáp ứng nhiều nhu cầu kiểm thử khác nhau trong suốt vòng đời phát triển. AWS SAM CLI cung cấp khả năng testing cục bộ tuyệt vời cho từng Lambda function, xử lý hiệu quả các kịch bản unit testing. Đối với integration testing, LocalStack integration cho phép kiểm thử các workflow đa dịch vụ cục bộ mà không cần phải đối mặt với sự phức tạp của IAM permissions, cấu hình Amazon VPC, hoặc các vấn đề về service boundary vốn có thể làm chậm tốc độ phát triển.\nKhi developers cần test với các AWS services trong môi trường phát triển, họ có thể sử dụng tính năng remote debugging, tính năng này cung cấp quyền truy cập đầy đủ vào Amazon VPC resources và IAM roles. Cách tiếp cận theo tầng này giúp developers tập trung vào business logic trong các giai đoạn phát triển ban đầu bằng LocalStack, sau đó chuyển đổi liền mạch sang kiểm thử dựa trên cloud khi cần validate hành vi và cấu hình của AWS services. Sự tích hợp này loại bỏ nhu cầu phải chuyển đổi giữa nhiều công cụ và môi trường, giúp developers xác định và khắc phục vấn đề nhanh hơn, đồng thời vẫn duy trì tính linh hoạt trong việc lựa chọn phương pháp testing phù hợp với nhu cầu cụ thể.\nĐã sẵn sàng để sử dụng Bạn có thể bắt đầu sử dụng các tính năng mới này thông qua AWS Toolkit for VS Code bằng cách cập nhật lên phiên bản v3.74.0. LocalStack integration hiện đã khả dụng tại tất cả các commercial AWS Regions ngoại trừ AWS GovCloud (US) Regions. Để tìm hiểu thêm, hãy truy cập tài liệu của AWS Toolkit for VS Code và Lambda documentation.\nĐối với các developer cần phạm vi dịch vụ rộng hơn hoặc các khả năng nâng cao, LocalStack cung cấp thêm các tier với nhiều tính năng mở rộng. Không có chi phí bổ sung từ AWS khi sử dụng integration này.\nNhững cải tiến này đánh dấu một bước tiến quan trọng khác trong cam kết liên tục của chúng tôi nhằm đơn giản hóa trải nghiệm phát triển serverless. Trong năm qua, chúng tôi đã tập trung biến VS Code trở thành công cụ lựa chọn hàng đầu cho các serverless developer, và LocalStack integration tiếp tục hành trình đó bằng cách cung cấp các công cụ giúp developer xây dựng và kiểm thử ứng dụng serverless hiệu quả hơn bao giờ hết.\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Xây dựng kiến trúc backup tập trung cross-Region với AWS Control Tower Bởi Chris Falk, Lei Shi, và Pujah Goviel | vào ngày 11 THÁNG 9, 2025 | trong Advanced (300), AWS Backup, AWS Control Tower, AWS Key Management Service (KMS), AWS Organizations, Best Practices, Enterprise governance and control, Resilience, Storage | Permalink | Bình luận\nQuản lý bảo vệ dữ liệu ở quy mô lớn là một thách thức quan trọng đối với các doanh nghiệp hiện đại. Khi tổ chức phát triển, dữ liệu của họ ngày càng phân tán, khiến cho việc triển khai các chính sách hỗ trợ nhất quán để đảm bảo phạm vi bao phủ toàn diện trở nên khó khăn. Các nhóm IT phải cân bằng giữa những yêu cầu cạnh tranh như tuân thủ quy định, bảo vệ tài nguyên và hiệu quả vận hành – đồng thời phải đối mặt với khó khăn trong việc xác thực và điều phối quy trình hỗ trợ trên một hạ tầng số ngày càng mở rộng.\nAWS Backup mang đến một giải pháp mạnh mẽ cho những thách thức này với một dịch vụ tập trung, được quản lý hoàn toàn, giúp đơn giản hóa việc bảo vệ dữ liệu ở quy mô lớn. Doanh nghiệp có thể tận dụng AWS Organizations cùng với AWS Backup để triển khai các chính sách backup tự động và nhất quán trên toàn bộ môi trường cloud của họ. Sự tích hợp với AWS Control Tower còn đơn giản hóa quá trình này hơn nữa bằng cách cho phép tổ chức tích hợp quản lý backup trên toàn doanh nghiệp trực tiếp vào multi-account landing zone được thiết kế theo kiến trúc chuẩn.\nTrong bài viết này, chúng tôi sẽ trình bày cách triển khai AWS Backup thông qua tích hợp với AWS Control Tower. Chúng tôi sẽ khám phá kiến trúc, các prerequisites, và quy trình triển khai từng bước. Bằng cách làm theo hướng dẫn này, bạn sẽ học cách tự động triển khai và quản lý các backup policies trên toàn tổ chức, giúp đáp ứng yêu cầu compliance, bảo vệ các critical resources, và giảm thiểu chi phí quản trị. Giải pháp này đặc biệt hữu ích cho các doanh nghiệp đang muốn chuẩn hóa hoạt động backup trong khi vẫn mở rộng môi trường cloud của mình.\nTổng quan giải pháp AWS Control Tower hiện cung cấp built-in capabilities để tối ưu hóa việc backup management ở quy mô lớn thông qua tích hợp trực tiếp với AWS Backup. Tính năng này sẽ tự động tạo một central backup vault trong mỗi AWS Region bên trong một central backup account chuyên dụng. Khi tổ chức của bạn mở rộng ra nhiều accounts và regions, AWS Control Tower sẽ tự động tạo các local backup vaults trong từng workload account thuộc các organizational units (OUs) đã được AWS Backup-enabled trên tất cả các governed AWS Regions. Bạn có thể tùy chỉnh chiến lược backup của mình bằng cách cấu hình backup policies để sao chép dữ liệu từ local vaults sang central vaults, có thể trong cùng một Region hoặc cross-Region. Ngoài ra, bạn không cần đến các custom deployment pipelines hoặc complex automation. Bạn có thể sử dụng AWS Backup policies để triển khai một chiến lược backup toàn diện, đáp ứng các yêu cầu cụ thể của tổ chức trong khi vẫn duy trì tính governance nhất quán trên toàn bộ môi trường AWS.\nĐiều kiện tiên quyết Trước khi triển khai tích hợp AWS Control Tower và AWS Backup, hãy đảm bảo rằng bạn đã có sẵn các thành phần nền tảng sau:\nMột AWS Organization hiện có được governed bởi AWS Control Tower Quyền truy cập Administrative vào AWS Organizations management account Walkthrough Phần này sẽ hướng dẫn bạn qua các bước thực hiện giải pháp.\nBước 1: Cấp phát dedicated backup accounts Trước tiên, bạn cần tạo hai specialized accounts đóng vai trò là nền tảng cho hạ tầng backup của bạn:\nBackup administrator account: Tài khoản này quản lý backup policies và configurations cho toàn bộ tổ chức của bạn. Central backup account: Tài khoản này lưu trữ centralized backup vaults và các cross-account backup copies. Tạo hai accounts này thông qua Organizations console hoặc AWS Command Line Interface (AWS CLI). Không sử dụng AWS Control Tower Account Factory hoặc bất kỳ quy trình AWS account vending nào khác mà sẽ tự động enroll các new accounts vào AWS Control Tower governance. Ở bước ba, khi bạn enable AWS Backup trong AWS Control Tower, các accounts này sẽ được enrolled và tự động đưa vào Security OU.\nBước 2: Tạo một multi-Region AWS KMS Key Backup encryption là một yêu cầu bảo mật quan trọng trong các enterprise organizations. Hãy tạo một multi-Region AWS Key Management Service (AWS KMS) key trong management account của bạn để kích hoạt mã hóa dữ liệu backup khi lưu trữ (at rest) và đảm bảo khả năng cross-account backup an toàn. Key này cần được tạo trong AWS Control Tower Home Region và được replicate đến tất cả các governed AWS Regions. Multi-Region AWS KMS key này sẽ được sử dụng để mã hóa backups trong central backup account vaults, cũng như tất cả local vaults trong các workload accounts trên tất cả các Regions. Mặc dù bạn có thể tạo key này thủ công thông qua AWS Management Console, chúng tôi khuyến nghị sử dụng infrastructure as code (IaC) như (AWS CloudFormation, AWS Cloud Development Kit (AWS CDK) hoặc Terraform).\nTham khảo tài liệu AWS Control Tower để biết thêm chi tiết về cách tạo AWS KMS key policy liên quan.\nBước 3: Enable AWS Backup trong AWS Control Tower Bây giờ bạn có thể tích hợp AWS Backup với AWS Control Tower landing zone. Điều hướng đến AWS Control Tower console, chọn Landing zone settings, và chọn Update landing zone. Trong phần backup configuration, nhập hoặc chọn các thông tin sau:\nCentral backup account ID: ID gồm 12 chữ số của Central Backup account mà bạn đã tạo ở Bước 1. Backup administrator account ID: ID gồm 12 chữ số của backup administrator account mà bạn đã tạo ở Bước 1. KMS Key ARN: Amazon Resource Name (ARN) của AWS KMS key mà bạn đã tạo ở Bước 2. Bạn có thể chọn các accounts đã tạo ở Bước 1 và AWS KMS key ở Bước 2 từ drop-down list trong mỗi text box, như minh họa trong hình dưới đây.\nQuá trình landing zone update có thể mất từ 30–45 phút để hoàn tất. Khi hoàn thành, bạn sẽ thấy trạng thái AWS Backup là Enabled, và các accounts cùng AWS KMS keys mà bạn chỉ định sẽ xuất hiện trong AWS Control Tower console, như minh họa trong hình dưới đây.\nBước 4: Cấu hình service opt-in và enable delegated administrator Sau khi enable AWS Backup trong AWS Control Tower, cấu hình service opt-in trong AWS Backup console. Điều hướng đến AWS Backup console, chọn Settings, và trong danh sách Service opt-in:\nBật opt-in cho các dịch vụ cần thiết cho workloads mà bạn muốn bao phủ bằng AWS Backup, chẳng hạn như Amazon Relational Database Service (Amazon RDS), Amazon Elastic Compute Cloud (Amazon EC2), Amazon DynamoDB, Amazon Elastic Block Store (Amazon EBS), Amazon Elastic File System (Amazon EFS). Điều này phải được thực hiện thủ công trong AWS Backup console. Backup service opt-in là một cài đặt theo AWS Region, và bạn phải lặp lại quy trình này cho tất cả các AWS Control Tower governed AWS Regions. Cuối cùng, đặt backup administrator account làm delegated administrator để kích hoạt việc organization-wide backup task monitoring và quản lý backup policies từ tài khoản này, như minh họa trong hình dưới đây.\nBước 5: Enable AWS Backup baseline trên các OUs cụ thể Sau khi cấu hình xong hạ tầng core backup trước đó, bạn cần enable AWS Backup baseline trên các OUs mà bạn mong muốn. Điều hướng đến AWS Control Tower console, chọn Organization từ thanh điều hướng bên trái, chọn OU mà bạn muốn kích hoạt backup, sau đó tìm và bật tùy chọn AWS Backup on this OU, như minh họa trong hình dưới đây.\nThứ tự enablement là rất quan trọng, vì vậy khi enable AWS Backup baseline trên toàn tổ chức, hãy tuân theo cách tiếp cận theo hierarchy. Bắt đầu với các top-level OUs trước khi tiếp tục với các child OUs. Trong ví dụ minh họa trong hình dưới đây, bạn sẽ enable AWS Backup baseline trước trên Workloads top-level OU, sau đó tiếp tục với các child OUs như Workloads X, Workloads Y, v.v.\nBước 6: Gắn tag cho các resources để backup Bước cuối cùng trong quá trình triển khai của bạn là áp dụng tags cho các resources cần được backup.\nKhi bạn enable AWS Backup thông qua AWS Control Tower, một bộ default backup plans với các resource tags được định nghĩa sẵn sẽ tự động được tạo cho các bản backup theo giờ, ngày, tuần và tháng. Các kế hoạch này cung cấp mức bảo vệ hợp lý cho các kịch bản phổ biến. Tuy nhiên, hầu hết các doanh nghiệp sẽ muốn triển khai các custom backup plans dựa trên mức độ quan trọng của workload và các yêu cầu compliance bằng cách sử dụng AWS Organizations backup policies.\nDọn Dẹp Các bước sau sẽ hướng dẫn bạn dọn dẹp sau khi hoàn tất giải pháp này.\nBước 1: Tắt backup baseline trên các OUs cụ thể Trước khi gỡ tích hợp ở cấp landing zone, bạn nên disable backup controls tại từng OU trước.\nĐiều hướng đến AWS Control Tower console Chọn Organization từ thanh điều hướng bên trái Theo thứ tự ngược lại với quá trình enablement, bắt đầu từ các child OUs trước rồi tiếp tục đến các parent OUs: a. Chọn OU b. Chọn tab Controls c. Tìm và disable tùy chọn AWS Backup on this OU Bước 2: Gỡ tích hợp AWS Backup Bây giờ bạn đã sẵn sàng để gỡ tích hợp AWS Backup khỏi AWS Control Tower landing zone của mình.\nĐiều hướng đến AWS Control Tower console Chọn Landing zone settings Chọn Update landing zone Trong phần backup configuration, chọn AWS Backup is not enabled Chọn Next, xem lại các thay đổi, sau đó chọn Update landing zone để áp dụng các thay đổi này AWS Control Tower sẽ gỡ tích hợp trong khi vẫn giữ nguyên backup data hiện có của bạn, như minh họa trong hình dưới đây.\nBước 3: Dọn dẹp các resources bổ sung Sau khi gỡ tích hợp, bạn có thể muốn dọn dẹp thêm các resources:\nLên lịch deletion cho AWS KMS key đã tạo Xóa bất kỳ AWS Identity and Access Management (IAM) roles liên quan đến backup mà không còn cần thiết Quyết định xem có repurpose hay đóng các dedicated backup accounts Xóa bất kỳ recovery points và vaults nào không còn cần thiết Theo mặc định, việc gỡ tích hợp AWS Backup sẽ không xóa các backup vaults hoặc recovery points hiện có của bạn. Điều này được thiết kế nhằm ngăn ngừa mất dữ liệu ngoài ý muốn trong quá trình thay đổi cấu hình. Tuy nhiên, điều này có nghĩa là bạn phải quản lý các resources này một cách rõ ràng nếu muốn xóa chúng.Để quản lý các backup vaults và recovery points sau khi gỡ tích hợp, điều hướng đến AWS Backup console trong central backup account của bạn, và chọn Backup vaults từ thanh điều hướng bên trái. Để xóa toàn bộ vault và tất cả các recovery points, trước tiên xóa tất cả recovery points bên trong vault, sau đó chọn vault và chọn Delete.\nKết Luận Bằng cách tích hợp AWS Backup với AWS Control Tower, bạn có thể tự động hóa và chuẩn hóa việc bảo vệ dữ liệu trên toàn bộ tổ chức mà không cần phát triển tùy chỉnh. Các tổ chức sử dụng AWS Control Tower có thể enable AWS Backup như một baseline landing zone service để tự động tạo backup vaults và triển khai policies trên nhiều accounts và AWS Regions, đảm bảo bảo vệ dữ liệu nhất quán trong khi giảm bớt khối lượng quản trị. Cách tiếp cận quản lý tập trung giúp tối ưu hóa hoạt động, trong khi các tùy chọn policies linh hoạt cho phép bạn tùy chỉnh chiến lược bảo vệ phù hợp với nhu cầu kinh doanh cụ thể. Quan trọng nhất, giải pháp này nâng cao khả năng resilience tổng thể của dữ liệu thông qua các best practices tích hợp sẵn. Khi môi trường cloud của bạn mở rộng, bạn có thể yên tâm duy trì các thực hành backup mạnh mẽ, nhất quán và phù hợp với các nguyên tắc well-architected.\nTAGS: AWS Backup, AWS Cloud Storage, AWS Control Tower, AWS Key Management Service (AWS KMS), data resiliency "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Hiểu và xây dựng các trang bị cần có cho việc học cloud cơ bản tại AWS.\nTuần 2: Làm quen với Amazon VPC(Virtual Private Cloud) và VPN - DirectConnect - LoadBalancer - ExtraResources.\nTuần 3: Hiểu về cách chạy và kết nối với các dịch vụ máy ảo của AWS.\nTuần 4: Dịch vụ máy tính ảo VM trên AWS.\nTuần 5: Dịch vụ lưu trữ trên AWS.\nTuần 6: Dịch vụ bảo mật trên AWS.\nTuần 7: Dịch vụ cơ sở dữ liệu trên AWS.\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu cần làm tuần 1: Lên văn phòng cùng team và hiểu nội quy của văn phòng. Hiểu cách viết workshop. Tìm hiểu AWS tạo tài khoản. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Hiểu rõ nội quy của văn phòng và thực hiện đúng cho những buổi sau 08/09/2025 09/09/2025 2 - Viết workshop cách tạo sườn 10/09/2025 13/09/2025 https://www.youtube.com/watch?v=mXRqgMr_97U\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=3 3 - Tạo tài khoản AWS và làm nhiệm vụ nhận 200 credit free - Thực hành sơ bộ với các nhiệm vụ nhận 200$ 14/09/2025 14/09/2025 4 - Học và hiểu về cloud 15/09/2025 17/09/2025 https://www.youtube.com/watch?v=HxYZAK1coOI\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=4 5 - Thực hiện tạo IAM user để admin user và admin group 16/09/2025 16/09/2025 https://www.youtube.com/watch?v=b9pK1oG534Q\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=13 Kết quả đạt được tuần 1: Lên văn phòng kết nối được với các đồng nghiệp cùng làm tại AWS First Cloud Journey, Làm quen được với 2 bạn học về 1 bạn học BE và 1 bạn Chung ngành khác nhóm.\nĐã chạy được hugo và test thành công, hiểu được cách viết của workshop hỗ trợ cho việc viết cho các tuần sau cũng cung như proposal và translated blogs(Done và hiểu).\nHiểu về cloud là gì:\nLà sự phân phối tài nguyên Công Nghệ Thông Tin thông qua Internet. Thanh toán tài nguyên theo mức độ sử dụng. Tối ưu hóa được chi phí, xài bao nhiêu tính bấy nhiêu, tốc độ nhanh. Linh hoạt trong việc thêm hoặc bớt tài nguyên 1 cách hợp lý. Quy mô rộng, ứng dụng trên toàn cầu. Để học được Cloud thì:\nKết bạn học hỏi cùng nhau, học từ các người đi trước Trải nghiệm và sử dụng các dịch vụ của AWS Học qua các nền tảng online học tư học Tạo tài khoản hiểu về AWS và các công cụ:\nTạo thành công tài khoản và nhận được 200$ sau khi làm các nhiệm vụ activate. Hiểu rõ root user và IAM user, root user là tài khoản gốc quản lý tất cả, IAM user được tạo ra bởi root user và được tài khoản gốc cấp quyền quản lý. Tạo MFA cho tài khoản đảm bảo an toàn bảo mật. Tạo user:\nĐể tạo vào console của AWS tìm kiếm IAM (Identity and Access Management). Sau đó thấy Dashboard của nó và chú ý đến hai yếu tố là User và User Group' Tạo User chọn User để tạo và bấm vào create user. Nhập tên user và tích chọn Provide user access to the AWS Management Console - optional, để tạo mật khẩu chọn user I want to create an IAM user =\u0026gt; I want to create an IAM user =\u0026gt; next Bấm next tiếp và create user Tạo user:\nTạo User Group vào console của AWS tìm kiếm IAM (Identity and Access Management). Chọn User Group =\u0026gt; Create user group =\u0026gt; Nhập tên group và tạo. Chọn vào group đã tạo, chon add user để add, chon user cần add và add user. "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Học và hiểu VPC,VPN là gì Cách tạo, kết nối và hoạt động của dịch vụ mạng Chạy được 1 server ảo Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Tìm hiểu khái niệm VPC, VPN tập 11/08/2025 11/08/2025 2 - Thực hành: Sử dụng dịch vụ của AWS với VPC, VPN 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tạo Subnets, Internet Gateway 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo Route Table, security groups 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tạo Route Table, Security groups 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Hiểu khái niệm VPC và VPN:\nAmazon VPC: Cho phép tạo 1 mạng riêng ảo, khởi tạo các tài nguyên ảo của AWS như là máy chủ ảo, mạng ảo và có quyền quản lý riêng, 1 VPC cho phép chạy nhiều AZ khác nhau VPC chỉ được nằm trong 1 Region, khi khởi tạo và khai báo phải có 1 lớp mạng IPv4 là bắt buộc, IPv6 là tùy chọn không bắt buộc\nMax của VPC là đucợ 5VPC trong 1 Region và 1 Account.\nMục đích dùng phân tách môi trường (Production, Dev, Test, Staging).\nChia máy ảo và chia thành các mạng con, vàn tập con này chỉ năm trong 1 AZ cụ thể và chỉ định CIDR cho mạng con đó là 1 tập còn của khối VPC CIDR.\ntập con có 5 IP:\nĐịa chỉ Network (10.10.1.0). Địa chỉ Boardcast (10.10.1.255). Địa chỉ cho bộ tuyến tính (10.10.1.1). Địa chỉ DNS (Domain Name System) (10.10.1.2). Địa chỉ cho tính toán tương lai (10.10.1.3). Bảng định tuyến(Route Table):\nTập hợp các Route, xác định đường đi cho mạng. Default Route Table là mặc định không xóa được, chứ duy nhất 1 Route cho phép các tập con VPC kết nối với nhau, Route Table sẽ được gán cho tập con. Custom Route Table để tạo và không xóa default route được. ENI (Elastic Network Interface) là card mạng ảo giúp chuyển sang EC2:\nKhỉ chuyển máy chủ mới, ENI giúp mạng ảo đảm bảo vẫn sẽ duy trì. Địa chỉ IP private. Địa chỉ Elastics IP address. Địa chỉ MAC. VPC Endpoint: Mục đích cho phép kết nối với các tài nguyên trong VPC mà không cần internet, có 2 loại VPC Endpoint: Interface Endpoint sử dụng cho và Gateway Endpoint.\nVPC Security Group: Là 1 tường lửa ảo giúp lưu trữ trạng thái giúp kiểm soát lượng truy cạp đến AWS.\nHạn chế Security Group rule: Địa chỉ nguồn, Cổng kết nối, Security Group khác. Security Group rule chỉ cho phép rule allow, được áp dụng trên các ENI. Network Access Control List(NACL): Là tưởng ảo không lưu trữ trạng thái, giúp kiểm soát lượng truy cập đến và đi.\nHạn chế NACL: Địa chỉ nguồn và Cổng kết nối. Áp dụng cho VPC Subnet. Mặc định NACL chỉ cho phép mọi truy cập đến và đi. VPC Flow Logs: là tính năng cho phép nắm bắt thông tin về IP đến và đi.\nCác tập sẽ được đưa lên Amazon CloudWatch Logs hoặc S3. Không capture nội dung gói tin. VPC Peering: là tính năng giúp các VPC kết nối với nhau, kết nối cần tạo 1:1 giữa hai VPC và không hỗ trợ hai VPC bị overlap IP address space.\nTransit Gateway: dùng để kết nối các VPC với nhau.\nVPN Site to Site dùng cho mô hình hybrid tạo liên kết liên tục.\nVPN Client to Site cho phép truy cập 1 host với tài nguyên VPC\nDirect Connect cho phép kết nối riêng, độ trễ 20ms-30ms\nElastic Load Balancing là dịch vụ cân bằng quản lý bởi AWS Sử dụng HTTP, HTTPS, TCP(bảo mật), SSL, có thể public hoặc private có 4 loại ELB: Application Load Balancer, Network Load Balancer, Classic Load Balancer, Gateway Load Balancer Thực hành:\nTìm kiến VPC =\u0026gt; create vpc =\u0026gt; đặt tên Chọn IPv4 và nhập địa chỉ 10.10.0.0/16 Tạo Subnets Tạo Internet gateways Tạo Security groups "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: KLàm quen với EC2 cách tạo và kết nối EC2. Thiết lập Hybrid DNS với Route Table và kết nối EC2 với Endpoint. Chạy EC2 và kiểm tra chạy môi trường. Xóa tài nguyên sau khi làm xong. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Tạo EC2 với Subnets, kiểm tra kết nối, Tạo NAT Gateway. 21/09/2025 22/09/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i 2 - Kết nối EC2 với Endpoint, tạo key pair và DNS. 24/09/2025 25/09/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i 3 - Tạo Route 53: Resolver Rules, Inbound Endpoints 27/09/2025 28/09/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i 4 - Kiểm tra kết quả và xóa tài nguyên. 28/09/2025 28/09/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i Kết quả đạt được tuần 3: Tạo được EC2: kết nối trên AWS trước, sau đó kết nối bằng PuTTy để kết nối với CLI để kiểm tra và nhập user login vào để đăng nhập. "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Tìm hiểu về máy tính ảo trên AWS . Có các hệ điều hành nào và cái nào dùng phổ biến nhất trên AWS. EC2 được điều hành như thế nào và tại sao lại dùng nhiều. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Amazon Elastic Compute Cloud ( EC2 ) - Instance type AWS. 29/09/2025 29/09/2025 2 - Amazon Elastic Compute Cloud ( EC2 ) - AMI / Backup / Key Pair EC2. 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Amazon Elastic Compute Cloud ( EC2 ) - Elastic block store. 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Amazon Elastic Compute Cloud ( EC2 ) - Instance store 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Amazon Elastic Compute Cloud ( EC2 ) - User data 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Amazon Elastic Compute Cloud ( EC2 ) - Meta data 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 7 - Amazon Elastic Compute Cloud ( EC2 ) - EC2 auto scaling 1/10/2025 1/10/2025 https://cloudjourney.awsstudygroup.com/ 8 - EC2 Autoscaling - EFS/FSx - Lightsail - MGN 1/10/2025 1/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 4: Khái niệm máy ảo và các dịch vụ về máy ảo:\nAmazon Elastic Computer Cloud (EC2) Amazon Lightsail Amazon EFS/FSX AWS Application Migration Service(MGN) Amazon Elastic Compute Cloud (EC2):\nEC2 là dịch vụ về máy ảo và nó gần giống với máy chủ vật lý và máy chủ ảo truyền thống. Nhưng EC2 khởi tạo nhanh hơn, khả năng co giãn tài nguyên linh hoạt hơn.\nEC2 có thể hỗ trợ các workload để lưu trữ website, ứng dụng, cơ sở dữ liệu và các dịch vụ nào máy chủ truyền thống làm được thì EC2 điều làm được.\nĐể được gọi là Instance type phải có đủ yếu tố như sau.\nCPU/GPU. Memory. Network. Storage AMI(Amazon Machine Image)/Backup/Keypair.\nAMI(Amazon Machine Image) dùng để provisitor ra 1 hoặc nhiều EC2 Instance cùng 1 lúc. AMI có sẵn của AWS, trên AWS Market Place và custom AMI tự tạo từ EC2 Instances. AMI bao gồm root OS volumes, quyền sử dụng AMI quy định tài khoản AWS được sử dụng và mapping EBS volume sẽ được tạo và gán vào EC2 Instances. EC2 instance có thể được backup bằng cách tạo snapshot. Key pair (public key và private key) dùng để mã hóa thông tin đăng nhập cho EC2 Instances. Elastic block store.\nAmazon EBS cung cấp block storage và được gắn trực tiếp vào EC2 Instance, tuy được gắn trực tiếp như 1 RAW device, EBS về bản chất hoạt động độc lập với EC2 và được kết nối thông qua mạng riêng của EBS. EBS có hai nhóm đĩa chính là HDD và SSD, được thiết kế để đạt độ sẵn sàng 99.999% bằng cách replicate dữ liệu giữa 3 Storage Node trong 1 AZ. Có một số EC2 Instances đặc thù được tối ưu hóa hiệu năng của EBS. (Optimized EBS Instances) EBS volumes, mặc định chỉ được gắn vào 1 EC2 Instances, EC2 Instances chạy trên Hypervisor Nitro có thể dùng 1 EBS volume gắn vào nhiều EC2 Instances. (EBS Multi attach) EBS được backup bằng cách thực hiện snapshot vào S3 (Simple Storage Service). Snapshot đầu tiên là full, tất cả các snapshot tiếp theo là incremental. Instance store là vùng dữ liệu NVMe tốc độ cao, nằm trên physical node chứa các máy ảo EC2.\nInstance store sẽ bị xóa hết dữ liệu khi chương trình ta thực hiện stop EC2 instance. nstance store không bị xóa dữ liệu khi chương trình ta thực hiện restart máy, nhưng bị crash. Instance store không replicate dữ liệu để phòng né tránh trường hợp khuyên kích lưu trữ dữ liệu quan trọng. Sử dụng trong môi trường eps thi điều co môt cai tinh @trieu lops Khi sử dụng thường dự replicate dữ liệu vào một EBS volume để bảo đảm an toàn. EC2 user data là đoạn script chạy một lần khi provision EC2 instance từ AMI.\nTùy hệ điều hành máy chủ ta sẽ dùng bash shell scripts (Linux) / powershell (Windows). EC2 Metadata, là các thông tin liên quan đến bàn thân EC2 instances, ví dụ địa chỉ IP Private, Public, Hostname, Security groups\u0026hellip;.\nEC2 Auto Scaling là tính năng hỗ trợ tăng giảm số lượng EC2 Instance dựa theo các điều kiện cụ thể (scaling policy).\nEC2 Auto Scaling có thể đăng ký các EC2 Instance vào Elastic Load Balancer. EC2 Auto Scaling hoạt động trên nhiều AWS Availability Zone. EC2 Auto Scaling có thể hỗ trợ Pricing options khác nhau. EC2 Autoscaling - EFS/FSx - Lightsail - MGN:\nEC2 bao gồm 4 tùy chọn giá. On-demand Trả theo giờ / phút / giây, xài nhiêu tính nhiêu, máy nhật. Phù hợp cho các workload chạy lén tối 6 tiếng 1 ngày. Reserved Instance : Cam kết sử dụng theo kì han 1-3 năm để lấy discount, tuy nhiên bị giới hạn theo EC2 Instance type/family. Saving Plans : Cam kết sử dụng theo kì han 1-3 năm để lấy discount, có thể ko bị giới hạn bộ EC2 Instance type family. Spot Instance : Tận dụng tài nguyên dư, giá rẻ tùy nhiên khi cán thị AWS sẽ terminate instance trong 2 phút. Amazon Lightsail. Là dịch vụ tính toán chi phí thấp (giá tính theo tháng, bắt đầu từ 3.5 USD/tháng). Ngoài ra, mỗi Instance Lightsail tạo ra cũng sẽ có một mức data transfer đi kèm (data transfer này có mức giá rẻ hơn so với data transfer từ EC2 khá nhiều). Amazon Lightsail phù hợp cho các workload nhẹ, môi trường test/dev, không yêu cầu CPU cao liên tục (hơn 2 giờ mỗi ngày). Amazon Lightsail cũng có khả năng backup bằng snapshot tương tự như EC2. Amazon Lightsail chạy trong một môi trường VPC độc lập và có thể kết nối với VPC thông qua việc thiết lập VPC Peering. Amazon EFS/FSX. EFS EFS (Elastic File System) cho phép tạo các NFSv4 Network volume và gắn vào nhiều EC2 Instances cùng lúc, quy mô lưu trữ lên đến hàng petabyte. EFS chỉ support Linux. Sử dụng EFS chỉ tính chi phí theo dung lượng sử dụng (trong khi EBS tính phí theo dung lượng cấp phát). EFS có thể được cấu hình để mount vào môi trường on-premise qua DX hoặc VPN. FSX FSx cho phép tạo các NTFS volume và gắn vào nhiều EC2 Instances cùng lúc sử dụng giao thức SMB (Server Message Block), FSx support Windows và Linux. Sử dụng FSx chỉ tính chi phí theo dung lượng sử dụng (trong khi EBS tính phí theo dung lượng cấp phát). FSx hỗ trợ tính năng deduplication, giúp giảm chi phí 30-50% cho các trường hợp sử dụng thông thường. AWS Application Migration Serveice(MGN):\nAWS Application Migration Service (MGN) được dùng để migrate và replicate nhằm mục đích xây dựng Disaster Recovery Site cho các máy chủ thực, vào trong môi trường AWS. Application Migration Service (MGN) liên tục sao chép các máy chủ nguồn sang EC2 Instances trên tài khoản AWS (asynchronous/synchronous). Trong quá trình sao chép, MGN sẽ sử dụng các máy staging có số lượng và quy mô cấu hình nhỏ hơn máy chủ gốc rất nhiều. Khi thực hiện cut-over, MGN sẽ dừng và khởi chạy các máy chủ EC2 trên AWS. "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Amazon Simple Storage Service ( S3 ) - Access Point - Storage Class. S3 Static Website \u0026amp; CORS - Control Access - Object Key \u0026amp; Performance - Glacier. Snow Family - Storage Gateway - Backup. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Làm quen Amazon Simple Storage Service (S3) 2/010/2025 2/010/2025 2 - Amazon Simple Storage Service (S3) - Access Point 2/010/2025 2/010/2025 https://cloudjourney.awsstudygroup.com/ 3 - Amazon Simple Storage Service (S3) - Storage Class 2/010/2025 2/010/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu S3 Static Website \u0026amp; CORS 3/010/2025 3/010/2025 https://cloudjourney.awsstudygroup.com/ 5 - Control Access - Object Key \u0026amp; Performance - Glacier 3/010/2025 3/010/2025 https://cloudjourney.awsstudygroup.com/ 6 - Snow Family - Storage Gateway - Backup 3/010/2025 4/010/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: Tìm hiểu Amazon Simple Storage Service (S3):\nAmazon S3 là nơi lưu trữ dữ liệu tĩnh, có nghĩa là những dữ liệu đã được tạo ra và không thay đổi sau đó. S3 phù hợp với các loại dữ liệu chỉ ghi một lần và đọc nhiều lần (WORM - Write Once Read Many). Amazon S3 không giới hạn tổng khối lượng dữ liệu lưu trữ. Mỗi đối tượng không được lớn hơn 5 TB. Theo mặc định, dữ liệu trong Amazon S3 được nhân bản trên 3 AZ trong 1 Region. Amazon S3 có khả năng kích hoạt sự kiện (trigger event) cho phép bạn kích hoạt các hành động khi một sự kiện xảy ra, như tải lên hoặc xóa một đối tượng khỏi một vùng lưu trữ cụ thể. Amazon S3 được thiết kế để đạt độ bền (durability) 99.99999999% và độ sẵn sàng (high availability) 99.99%. Amazon S3 hỗ trợ multipart upload để upload các đối tượng lớn lên bucket. Chương trình tạo các S3 bucket để có thể lưu trữ các đối tượng trong Amazon S3. s3.amazonaws.com =\u0026gt; s3.amazonaws.com/capture.mp4 Amazon Simple Storage Service (S3) - Access Point: Amazon S3 Access Point là tính năng cho phép tạo các điểm kết nối (hostname unique) dành cho ứng dụng, người dùng hoặc nhóm.\nChương trình có thể cấu hình phân quyền khi tạo mỗi access point. Amazon Simple Storage Service (S3) - Storage Class:\nAmazon S3 chia vùng lưu trữ ra nhiều lớp lưu trữ (storage class) giúp chúng ta tối ưu hóa chi phí. Các cấp lưu trữ (Storage Class của S3): S3 Standard: Dữ liệu được truy cập thường xuyên. S3 Standard IA: Dữ liệu ít được truy cập thường xuyên. S3 Intelligent Tiering: Tự động di chuyển các đối tượng giữa các cấp lưu trữ theo số ngày đổi. S3 One Zone IA: Dữ liệu có thể tái tạo, dữ liệu trong vùng, ít được truy cập thường xuyên nhưng cần truy cập nhanh. Amazon Glacier / Deep Archive: Lưu trữ dữ liệu ít truy cập. Chức năng cấu hình thời gian lưu trữ dữ liệu (Object Life Cycle Management): Di chuyển dữ liệu trong Amazon S3. Bảng chứa dữ liệu trong các trường hợp sau đây, chuyển dữ liệu trong S3 bucket khi dữ liệu lưu trữ theo thời gian (ngày) đủ điều kiện. Amazon Simple Storage Service (S3) - Static Website \u0026amp; CORS:\nAmazon S3 có tính năng cho phép host các static website (html, media, \u0026hellip;), phù hợp cho Single Page Application. (ứng dụng web hoạt trang web tĩnh tác vụ người dùng bằng cách tạo lại trang web hiện tại với dữ liệu mới từ máy chủ web sử dụng javascript hoặc các framework của nó như AngularJS, ReactJS, thay vì phương pháp mặc định cua trình duyệt web tải toàn bộ trang mới). Amazon S3 hỗ trợ CORS. CORS là một cơ chế cho phép nguồn tài nguyên khác nhau (fonts, Javascript, v.v\u0026hellip;) của một trang web có thể được truy vấn từ domain khác với domain của trang đó. CORS là viết tắt của Cross-origin resource sharing. Amazon Simple Storage Service (S3) - Control Access:\nAmazon S3 có 2 cơ chế kiểm soát quyền truy cập tới bucket: S3 Access Control List (ACL) là một cơ chế kiểm soát truy cập cơ bản. Tuy nhiên, nếu bạn đã sử dụng S3 ACL và thấy không cần thay đổi, ACL S3 được gắn bucket và object của S3. Không xác định tại khoảnh khắc nào AWS sẽ dùng cơ chế này để cấp quyền truy cập thông qua loại quyền truy cập. S3 Bucket Policy và IAM policy xác định quyền cấp đối tượng bằng cách cung cấp các điều kiện áp dụng cho các đối tượng trong phần Resource trong policy này. Cấu hình này áp dụng cho các đối tượng trong bucket. Việc này cũng cấp quyền điều chỉnh các điều kiện trong bucket (trái ngược với ACL S3) giúp bạn điều chỉnh quyền truy cập. Amazon Simple Storage Service (S3) - Object Key \u0026amp; Performance:\nMối object trong S3 được ngang hàng, không phân cấp (hierarchy) và được gán 1 object key. Ví dụ: /image/sample.jpg, sample.jpg. Sâu bên trong S3 chia ra các Partitions, Partitions sẽ được chia ra tùy theo kích thước request tăng cao dựa trên số lượng S3 object keys lớn. (lắm chấm để điều khiển object trong partition). S3 lưu trữ key map (key map cung cấp chia ra nguồn partition dựa trên hash bộ prefix – tiền tố của object key). Để tối ưu S3 performance có thể dùng random prefix (/fscd/img/sample.jpg thay vì /img/sample.jpg). Mục tiêu của việc làm này là khiến S3 lưu trữ các object trên nhiều partitions nhất có thể vi performance của S3 dựa trên số lượng partitions. Amazon Simple Storage Service (S3) - Glacier:\nAmazon S3 Glacier là lựa chọn lưu trữ với chi phí thấp, phù hợp với dữ liệu không cần truy suất thường xuyên, lưu trữ lâu dài. Nếu bạn cần truy cập nhanh chóng hoặc thường xuyên, hãy chọn Amazon S3. Khi lưu trữ dữ liệu trong Amazon S3 Glacier, bạn không thể truy xuất dữ liệu trực tiếp mà phải đưa (retrieve) dữ liệu về từ một S3 Bucket. Có ba tùy chọn để truy xuất dữ liệu với thời gian truy cập khác nhau: Truy xuất Nhanh (Expedited): Hoàn tất trong vòng 1 - 5 phút. Truy xuất Tiêu chuẩn (Standard): Hoàn tất trong vòng 3 - 5 giờ. Truy xuất Hàng loạt (Bulk): Hoàn tất trong vòng 5 - 12 giờ. Snow Family:\nSnowball: Dịch vụ hỗ trợ migrate dữ liệu từ môi trường on-premise tới AWS ở quy mô lên đến PetaByte (PB). Mỗi Snowball có thể chứa tối đa 80 TeraByte (TB). Snowball sẽ được ship tới các AWS region mà chúng ta lựa chọn để lưu trữ dữ liệu vào trong S3 hoặc Glacier. Chương trình sử dụng Snowball Client tại máy local để thu thập dữ liệu, rồi chuyển dữ liệu qua transfer. Snowball Edge: Dịch vụ hỗ trợ migrate dữ liệu từ môi trường on-premise tới AWS ở quy mô lên đến PetaByte (PB). Mỗi Snowball Edge có thể chứa tối đa 100 TeraByte (TB). Snowball Edge sẽ được ship tới các AWS region mà chúng ta lựa chọn để lưu trữ dữ liệu vào trong Glacier hoặc S3. Chương trình sử dụng Snowball Client tại máy local để thu thập dữ liệu, rồi chuyển dữ liệu qua transfer. Snowball Edge là thiết bị được sử dụng để sao lưu dữ liệu từ các tài nguyên trong toàn bộ hệ thống khi import vào thiết bị. Snowmobile: Dịch vụ hỗ trợ migrate dữ liệu từ môi trường on-premise tới AWS ở quy mô lên đến 100 PByte. Mỗi Snowmobile có thể chứa tối đa 100 PB. Snowmobile sẽ được vận chuyển tới AWS region mà chúng ta lựa chọn để lưu trữ dữ liệu vào trong dịch vụ, với lựa chọn bao gồm S3 hoặc Glacier. Storage Gateway:\nAWS Storage Gateway là giải pháp lưu trữ Hybrid, kết hợp dung lượng lưu trữ trên AWS với dung lượng lưu trữ tại chỗ (on-premise). Chương trình được thiết kế để dùng quy mô qua gia tăng hợp lý với các dịch vụ lưu trữ trên cloud để giúp lưu trữ các dữ liệu lớn trong thời gian yêu cầu lưu trữ lâu. AWS Storage Gateway hỗ trợ ba phương thức lưu trữ chính: tập tin, ổ đĩa và băng từ: Cổng kết nối tập tin (File Gateway) cho phép bạn lưu trữ và truy xuất đối tượng trong Amazon S3 bằng cách sử dụng giao thức tệp NFS hoặc SMB. Dữ liệu được ghi thường qua cổng kết nối tập tin này sẽ được truy cập trực tiếp trong S3. Cổng kết nối ổ đĩa (Volume Gateway) cung cấp lưu trữ bằng cách sử dụng giao thức iSCSI. Dữ liệu trong ổ đĩa được lưu trữ trong Amazon S3. Để truy cập ổ đĩa iSCSI trong AWS, bạn có thể tạo EBS snapshot (tùy chọn bản AWS Backup) để tạo ra thành EBS Volumes. Cổng kết nối băng từ (Tape Gateway) cung cấp cách sử dụng sao lưu dữ liệu bằng cách sử dụng giao thức VTL (iSCSI), các tape drive ảo và tape ảo. Dữ liệu tape ảo được lưu trữ trong Amazon S3 hoặc Glacier. Backup:\nAWS Backup là một dịch vụ quản lý các tác vụ sao lưu. Chúng ta có thể cấu hình và lập lịch (backup schedule), thời gian lưu trữ (backup retention) và giám sát hoạt động sao lưu cho các tài nguyên trên AWS bao gồm: Amazon EBS Amazon EC2 Cơ sở dữ liệu Amazon RDS Cơ sở dữ liệu DynamoDB Amazon EFS AWS Storage Gateway volumes "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Tìm hiểu dịch vụ bảo mật trên AWS. Quản lý danh tính và quyền truy cập của Amazon. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Amazon Cognito - AWS Organization 05/10/2025 05/10/2025 2 - AWS Identity Center - Amazon Key Management Service 05/10/2025 05/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - AWS Security Hub 06/10/2025 06/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 6: Mô hình Chia sẻ Trách nhiệm:\nMô hình chia sẻ trách nhiệm: Khi sử dụng dịch vụ trên nền tảng đám mây, việc bảo mật chia sẻ trách nhiệm giữa khách hàng và nhà cung cấp dịch vụ. Khách hàng sẽ chịu trách nhiệm cho việc bảo vệ dữ liệu, áp dụng các best practices, sử dụng các dịch vụ để đảm bảo việc bảo mật máy ảo, Hypervisor hoặc máy chủ dữ liệu. Trách nhiệm bảo mật sẽ thay đổi tùy vào tầng dịch vụ: Các dịch vụ cơ bản (IaaS) Các dịch vụ quản lý máy chủ (PaaS) Các dịch vụ quản lý toàn bộ AWS Quản lý danh tính và quyền truy cập của Amazon:\nTài khoản gốc: Tài khoản này có toàn quyền truy cập vào tất cả các dịch vụ và tài nguyên AWS, và có thể bổ sung thêm quyền vào các tài nguyên. Thông tin tài khoản: Đã liên kết (khi đăng ký account), Không bị giới hạn quyền. Best Practices: Tạo và sử dụng IAM Administrator User, Khóa thông tin xác thực của root user (chia sẻ người dùng), Đảm bảo renew thông tin domain qua email của root user. IAM là dịch vụ giúp bạn kiểm soát quyền truy cập vào các dịch vụ và tài nguyên trong AWS account của mình. IAM cho phép bạn tạo nhiều tài khoản người dùng (IAM user) với thông tin xác thực (credentials) và quyền hạn khác nhau. IAM Principal (chủ thể IAM) là một thực thể có thể thực hiện các hành động trên tài nguyên trong AWS account của bạn. AWS account and root user IAM users Federated users (sử dụng web identity hoặc SAML federation) IAM roles Assumed-role sessions AWS services Anonymous users (không khuyến nghị) Người dùng IAM (IAM User) không phải là tài khoản AWS riêng biệt, IAM Users có thể được quản lý thông qua Management Console hoặc access key/secret key để thực hiện programmatic access (AWS CLI hoặc AWS SDK). IAM User khi được tạo ra mặc định không có bất cứ quyền nào. IAM User không được dùng để quản lý truy cập vào ứng dụng hay hệ thống khác. Đề cập quyền cho IAM User chủ yếu thông qua việc gắn IAM Policy vào IAM User. Đề quản lý đề dành hơn cho việc gắn với một nhóm nhiều IAM User thông qua IAM Group. IAM Group không thể là thành viên của 1 IAM Group khác. AM Policy: IAM Policy có 2 loại Identity based Policy gắn với một IAM Principal. Resource based Policy gắn với một AWS Resource. Cách thực thi quyền của IAM luôn ưu tiên Deny so với Allow, nếu có Deny tương minh (explicit) thì dù có allow ở trên một IAM Policy khác thì vẫn luôn là Deny. IAM Role: Cho phép xác định một tập hợp quyền truy cập vào các tài nguyên (thông qua việc gắn IAM Policy vào IAM Role). IAM Role không có thông tin đăng nhập (credentials) để truy cập vào management console hay AWS CLI/SDK. Khi một IAM User muốn sử dụng IAM Role, IAM User sẽ có thể assume (đảm nhận) IAM Role, ngay sau khi assume role, quyền hạn tại user sẽ được thay bằng quyền đang được cấp cho IAM Role. Ngoài ra, thông tin xác thực bảo mật tạm thời sẽ được cấp cho IAM User hoặc một AWS Service để có thể truy cập tới các dịch vụ trên AWS. Việc assume role sẽ làm việc với AWS STS - Security Token Service giúp tạo ra các thông tin chứng thực tạm (tương tự như access key). Để một user có thể sử dụng IAM Role, IAM Role sẽ được gắn với một resource base IAM policy, hay còn gọi là IAM Role trust policy, quy định xem ai có thể sử dụng IAM Role. IAM Role thường được dùng trong trường hợp để đảm bảo nguyên tắc cấp quyền thông qua việc cấp quyền cho các AWS account khác truy cập tài nguyên của AWS account hiện tại. Ngoài việc sử dụng cho IAM User, IAM Role còn được sử dụng để cấp quyền truy cập các resource của AWS cho các AWS Service. Trường hợp sử dụng thường thấy là dùng IAM Role cấp quyền cho các ứng dụng chạy bên trong dịch vụ tính toán (EC2). Amazon Cognito - AWS Organization:\nAmazon Cognito: Là dịch vụ quản lý bộ AWS có chức năng xác thực, cấp phép và quản lý người dùng cho các ứng dụng web và di động. Người dùng có thể đăng nhập trực tiếp bằng tên người dùng và mật khẩu hoặc thông qua một bên thứ ba như Facebook, Amazon hoặc Google. Hai thành phần chính của Amazon Cognito là User Pool và Identity Pool. User Pool là nơi lưu trữ thông tin người dùng và cung cấp các tùy chọn đăng ký và đăng nhập cho người dùng ứng dụng. Identity Pool cấp cho người dùng quyền truy cập vào các dịch vụ AWS khác. AWS Organization: AWS Organizations giúp quản lý và điều hành tập trung môi trường gồm nhiều AWS account. AWS Organizations có thể tạo các tài khoản AWS mới, phân bổ tài nguyên, sắp xếp các AWS account theo OU (Organization Unit), đồng thời đơn giản việc thanh toán toàn tập trung (consolidated billing). AWS Organization có thể áp dụng chính sách kiểm soát dịch vụ (Service Control Policies) lên các OU hoặc các AWS account, SCP thiết lập giới hạn quyền tại các IAM User hoặc IAM role trong OU hoặc AWS account đó. SCP cung cấp khả năng thiết lập deny-based policy. AWS Identity Center (SSO):\nAWS Identity Center giúp quản lý quyền truy cập tới AWS account và các ứng dụng bên ngoài. Identity source có thể là tên trong AWS Identity Center hoặc được liên kết với Active Directory. (AWS Managed Microsoft AD, On-premises Microsoft AD thông qua Two way trust hoặc AD Connector) Permission Set xác định khả năng truy cập của User và Group tới các tài khoản AWS trong AWS Organization. Các quyền được lưu trữ trong AWS Identity Center và được cung cấp cho tài khoản AWS dưới dạng IAM roles. Bạn có thể gán nhiều quyền cho một User. Amazon Key Management Service(KMS):\nAWS Key Management Service giúp tạo và quản lý các encryption key, phục vụ cho mục đích encrypt/decrypt dữ liệu trên AWS. Encryption key luôn nằm trong AWS KMS, đảm bảo tiêu chuẩn FIPS 140-2. CMK ( Customer Managed Key ) đóng vai trò là tài nguyên chính trong AWS KMS. CMK có thể có kích thước tới 4KB. Tuy nhiên thông thường, chúng ta chỉ sử dụng CMK cho mục đích tạo, mã hóa và giải mã Data Key - loại khóa được dùng bên ngoài AWS KMS để mã hóa dữ liệu. AWS Security Hub: Là dịch vụ cho phép chuẩn hóa thực hiện kiểm tra bảo mật dựa trên các tiêu chuẩn và best practices.\nSecurity Hub chạy liên tục, kiểm tra các dịch vụ trong tài khoản AWS và kiểm tra bảo mật dựa trên các best practice của AWS và tiêu chuẩn ngành (VD: PCI DSS). Security Hub cung cấp kết quả kiểm tra dưới dạng điểm số và giúp chuẩn hóa xác định các tài khoản và tài nguyên có thể cần được chú ý. "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Các dịch vụ cơ sở dữ liệu trên AWS. Amazon RDS \u0026amp; Amazon Aurora. Redshift - Elasticache. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Khái niệm cơ sở dữ liệu 11/08/2025 11/08/2025 2 - Amazon RDS \u0026amp; Amazon Aurora 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 3 - Amazon ElastiCache \u0026amp; Amazon RedShift 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Khái niệm cơ sở dữ liệu:\nCơ sở dữ liệu(Database) là nơi lưu trữ thông tin để xử lý và phân tích dữ liệu từ nhiều nguồn khác nhau, hỗ trợ người dùng trong việc tra cứu thông tin một cách nhanh chóng và hiệu quả khi cần thiết, đặc biệt là trong các hệ thống phức tạp hoặc khi người dùng cần dịch khac nhau. Phiên(Session) là khoảng thời gian từ thời gian bắt đầu kết nối vào hệ thống CSDL (time start) đến thời gian kết thúc (time end) là khoảng thời gian bản ngắt kết nối. Khóa chính(Primary Key) là một cột (hoặc kết hợp các cột) được chỉ định để xác định duy nhất mỗi bản ghi trong bảng. Khóa ngoại(Foreign Key) là một cột (hoặc nhóm cột) trong bảng có thể quan hệ với cột trong một bảng khác, giúp tạo ra mối tham chiếu giữa các bảng và thiết lập liên kết giữa chúng. Chỉ mục(Index) cơ sở dữ liệu là một cấu trúc dữ liệu được xây dựng để cải thiện tốc độ của các hoạt động truy xuất dữ liệu (read) trên bảng cơ sở dữ liệu, tuy nhiên sẽ làm tăng chi phí ghi thêm (write) và không gian lưu trữ (storage) để duy trì cấu trúc dữ liệu chỉ mục. Các chỉ mục được sử dụng để định vị dữ liệu một cách nhanh chóng hơn khi truy cập bảng cơ sở dữ liệu. Chỉ mục có thể được tạo ra trên bảng cơ sở dữ liệu theo một cách khác nhau. Phân vùng(Partitions) là quá trình chia nhỏ dữ liệu trong các bảng lớn được chia ra để lưu trữ dữ liệu trên nhiều phân vùng khác nhau. Bằng cách này, các truy vấn có thể truy cập một phân vùng dữ liệu thay vì toàn bộ dữ liệu, giúp tăng tốc độ truy vấn và giảm chi phí khi xử lý các truy vấn lớn trên cơ sở dữ liệu. Kế hoạch thực thi truy vấn - Kế hoạch truy vấn(Execution Plan - Query Plan) là một chương trình hoặc các bước được sử dụng để thực thi truy vấn trong hệ quản trị cơ sở dữ liệu quan hệ SQL. Khi một truy vấn được gửi đến cơ sở dữ liệu, trình tối ưu hóa sẽ chọn phương án tốt nhất để thực thi truy vấn dựa trên các điều kiện và các yếu tố khác nhau, từ đó tối ưu hóa truy vấn và tối ưu hóa hiệu quả truy vấn. Database Log là một phần quan trọng trong thiết kế giải pháp cơ sở dữ liệu giúp bảo vệ tính toàn vẹn dữ liệu và phục hồi dữ liệu trong trường hợp xảy ra sự cố. Tất cả các thay đổi dữ liệu được ghi lại trong các bản ghi (log file) được liên kết với cơ sở dữ liệu. Bộ đệm(Buffers) là một vùng lưu trữ tạm thời trong bộ nhớ máy tính. Nó cho phép lưu trữ dữ liệu tạm thời khi di chuyển dữ liệu từ nơi này sang nơi khác. Bộ đệm cơ sở dữ liệu lưu trữ các bản sao của các khối dữ liệu. Thông thường bộ đệm được sử dụng để tăng tốc độ truy xuất (đọc dữ liệu từ buffer) hoặc giảm thời gian ghi dữ liệu vào buffer, sau đó buffer sẽ đồng bộ hóa với cơ sở dữ liệu. NOSQL Cơ sở dữ liệu NoSQL (hay còn gọi là \u0026ldquo;Không chỉ SQL\u0026rdquo;) thường không phải dạng bảng như cơ sở dữ liệu quan hệ. Cơ sở dữ liệu NoSQL có nhiều loại dựa trên mô hình dữ liệu của chúng. Các loại chính là tài liệu (document), khóa-giá trị (key-value), wide-column và graph - biểu đồ. Chúng cung cấp các lược đồ linh hoạt và mô hình quy mô được điều chỉnh phù hợp với lượng dữ liệu lớn và tải lượng người dùng cao. OLTP - Online Transaction Processing - Hệ thống OLTP nhằm bảo vệ và duy trì giao dịch trong cơ sở dữ liệu. Mỗi giao dịch liên quan đến các bản ghi cơ sở dữ liệu sẽ được tạo thành từ nhiều trường hợp khác nhau. Vì độ bảo mật hoạt động nhanh và trong thời gian thực, hệ thống OLTP thường được sử dụng để xử lý các giao dịch trong cơ sở dữ liệu OLTP thường xuyên. Nếu một giao dịch không thành công, logic hệ thống sẽ đảm bảo tính toàn vẹn dữ liệu. OLAP - Online Analytical Processing - OLAP áp dụng các truy vấn phục vụ cho việc phân tích dữ liệu lịch sử, thường được sử dụng để tổng hợp dữ liệu OLTP theo các nguồn khác, chẳng hạn như các báo cáo chi tiết, phân tích và các dự đoán theo thời gian. Trong OLAP, trong một khoảng thời gian, các truy vấn phục vụ này thường liên quan đến một hệ thống lớn hơn. Vì độ bảo mật hiệu suất trong việc phân tích dữ liệu lịch sử, cơ sở dữ liệu (data warehouse) OLAP cung cấp các khả năng phân tích nâng cao để sử dụng các công cụ báo cáo hoặc các công cụ phân tích khác nhau để xử lý dữ liệu trong kho dữ liệu và đưa ra các dự đoán chính xác hơn. Amazon RDS \u0026amp; Amazon Aurora:\nAmazon RDS: Là cơ sở dữ liệu được quản lý trên AWS, cung cấp chi phí thấp và khả năng mở rộng RDBMS, không thể truy cập vào các cơ sở dữ liệu cũ. Bao gồm Aurora, MySQL, Postgres SQL, MSSQL, Oracle, Maria. Amazon RDS cung cấp các tính năng: Tự động sao lưu. (các log của database – max 35 ngày) Tạo bản sao chi đọc (Read Replica) phục vụ cho các Read workload, (reporting). Read Replica có thể được gắn ra khỏi chuỗi thanht toán Primary node. Chạy với cơ chế tự động failover, Primary/Standby, hay còn gọi là cơ chế Multi-AZ. RDS thường được sử dụng cho các ứng dụng OLTP. RDS cung cấp tính năng mã hóa dữ liệu at rest và in transit. RDS cung cấp bảo vệ bổ tĩnh mạng tường lửa cùng với EC2 (Security Group và NACL). Thay đổi quy mô (Thay đổi instance size). Tự động tăng dung lượng lưu trữ (Storage Auto scaling). Amazon Aurora: Amazon Aurora là một công cụ cơ sở dữ liệu quan hệ được tối ưu hóa để hỗ trợ lưu trữ dưới dạng đám mây, với các bản ghi song song trên cơ sở dữ liệu. Nó được xây dựng dựa trên các hệ thống RDBMS với hai lựa chọn là MySQL và PostgreSQL. Aurora cung cấp một RDBMS dựa trên Amazon RDS với nhiều cải tiến nâng cao hơn so với RDS. Ngoại ra Amazon Aurora cung cấp các tính năng: Back Track – Phục hồi lại DB về thời điểm trước đó. Clone – Tạo bản sao. Global Database – 1 Master và Multi Read nằm ở các Region khác nhau. Multi Master – Multi Master database. Amazon ElastiCache \u0026amp; Amazon RedShift:\nAmazon RedShift: Là dịch vụ Data warehouse được quản lý bởi AWS. Lợi thế Postgre SQL nhưng được tối ưu cho OLAP. Redshift sử dụng kiến trúc Massively-Parallel Processing (MPP) Database, dữ liệu được chia (partition) và lưu trữ tại các Compute node (bao gồm cả compute/storage). Leader node nhận vai trò điều phối và tổng hợp truy vấn. Redshift lưu trữ dữ liệu dưới dạng columnar storage, phù hợp cho ứng dụng OLAP. Redshift sử dụng SQL với các driver JDBC, ODBC thông dụng. Hỗ trợ nâng tính năng để tối ưu hóa chi phí (Transient cluster, Redshift spectrum). Amazon ElastiCache: Là một dịch vụ được quản lý bởi AWS giúp tạo ra các cluster caching engines. Hiện ElastiCache hỗ trợ 2 engine là Redis và Memcached. Amazon ElastiCache sẽ trách nhiệm phát hiện và thay thế các node bị failed. Amazon ElastiCache thường được đặt trực tiếp trên CSDL để cache dữ liệu, giám sát cho phép CSDL. Với các workload với ứng dụng mới, ưu tiên sử dụng Redis. (tính năng đa dạng, hiệu năng tốt) Sử dụng ElastiCache yêu cầu phải viết lại quy trình caching logic trên ứng dụng. "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Team Super Beast Warrior(SBW) Batch-based Clickstream Analytics Platform 1. Tóm tắt điều hành Dự án này nhằm mục tiêu thiết kế và triển khai một Batch-based Clickstream Analytics Platform cho một trang web thương mại điện tử chuyên về máy tính và phụ kiện, sử dụng AWS Cloud Services. Hệ thống thu thập dữ liệu tương tác của người dùng (như clicks, searches, và page visits) từ website và lưu trữ chúng trong Amazon S3 dưới dạng raw logs. Cứ mỗi giờ, Amazon EventBridge sẽ kích hoạt AWS Lambda functions để xử lý và chuyển đổi dữ liệu trước khi tải chúng vào data warehouse được triển khai trên Amazon EC2.\nDữ liệu đã được xử lý sẽ được trực quan hóa thông qua R Shiny dashboards, cung cấp cho chủ cửa hàng các thông tin chi tiết về kinh doanh như mô hình hành vi khách hàng, mức độ phổ biến của sản phẩm, và xu hướng tương tác trên website.\nKiến trúc này tập trung vào batch analytics, ETL pipelines, và business intelligence, đồng thời đảm bảo bảo mật (security), khả năng mở rộng (scalability), và hiệu quả chi phí (cost efficiency) thông qua việc tận dụng AWS managed services.\n2. Tuyên bố vấn đề Vấn đề hiện tài là gì? Các E-commerce websites tạo ra một lượng lớn clickstream data — bao gồm product views, cart actions, và search activities — chứa đựng nhiều business insights có giá trị.\nTuy nhiên, các cửa hàng nhỏ và vừa (SMEs) thường thiếu hạ tầng (infrastructure) và chuyên môn kỹ thuật (expertise) để thu thập, xử lý và phân tích dữ liệu này một cách hiệu quả.\nDo đó, họ gặp khó khăn trong việc:\nHiểu hành vi mua hàng của khách hàng Xác định sản phẩm hoạt động hiệu quả nhất Tối ưu hóa chiến dịch marketing và hiệu suất website Đưa ra quyết định về tồn kho và định giá dựa trên dữ liệu Giải pháp Dự án này giới thiệu một AWS-based batch clickstream analytics hệ thống có khả năng tự động thu thập dữ liệu tương tác của người dùng từ website mỗi giờ, xử lý dữ liệu thông qua serverless functions, và lưu trữ vào central data warehouse trên Amazon EC2.\nKết quả sau khi xử lý được trực quan hóa bằng R Shiny dashboards, giúp chủ cửa hàng thu được actionable insights về hành vi khách hàng (customer behavior) và nâng cao hiệu suất kinh doanh tổng thể (overall business performance).\nLợi ích và hoàn vốn đầu tư Data-driven decision making: Khai thác customer preferences, popular products, và shopping trends để hỗ trợ ra quyết định dựa trên dữ liệu. Scalable and modular design: Thiết kế có khả năng mở rộng và mô-đun hóa, dễ dàng mở rộng để xử lý nhiều users hơn hoặc tích hợp thêm data sources mới. Cost-efficient batch processing: Giảm chi phí tính toán liên tục (continuous compute costs) bằng cách vận hành theo lịch trình định kỳ hàng giờ (scheduled, hourly basis). Business insight enablement: Trao quyền cho store owners tối ưu hóa sales strategies và cải thiện revenue thông qua evidence-based analytics. 3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.(cần bổ sung)\nDịch vụ AWS sử dụng Amazon Cognito: Xử lý user authentication và authorization cho cả administrators và website customers, đảm bảo truy cập an toàn vào e-commerce platform. Amazon S3: Đóng vai trò là lớp lưu trữ dữ liệu tập trung (centralized data storage layer) — lưu trữ static website front-end và raw clickstream logs được thu thập từ user interactions. Ngoài ra, S3 còn tạm thời lưu trữ các batch files trước khi chúng được xử lý và chuyển đến data warehouse. Amazon CloudFront: Phân phối nội dung website tĩnh (static website content) trên toàn cầu với độ trễ thấp (low latency), cải thiện trải nghiệm người dùng và lưu cache tài nguyên gần với khách hàng. Amazon API Gateway: Đóng vai trò là điểm vào chính (main entry point) cho các API calls từ website, cho phép gửi dữ liệu một cách an toàn (như clickstream hoặc browsing activity) vào hệ thống AWS. AWS Lambda: Thực thi serverless functions để tiền xử lý (preprocess) và tổ chức (organize) dữ liệu clickstream được tải lên S3. Lambda cũng xử lý các tác vụ chuyển đổi dữ liệu theo lịch trình (scheduled data transformation jobs) được EventBridge kích hoạt, trước khi tải vào data warehouse. Amazon EventBridge: Lên lịch và điều phối (schedules and orchestrates) các batch workflows — ví dụ, kích hoạt Lambda functions mỗi giờ để xử lý và di chuyển clickstream data từ S3 vào EC2 data warehouse. Amazon EC2 (Data Warehouse): Đóng vai trò là môi trường data warehouse, chạy PostgreSQL hoặc một relational database khác để phục vụ batch analytics, trend analysis, và business reporting. R Shiny (on EC2): Lưu trữ các interactive dashboards giúp trực quan hóa các insights đã được xử lý theo batch, hỗ trợ doanh nghiệp khám phá hành vi khách hàng (customer behavior), sản phẩm phổ biến (popular products), và cơ hội bán hàng (sales opportunities). AWS IAM: Quản lý quyền truy cập (access permissions) và chính sách (policies) nhằm đảm bảo rằng chỉ những người dùng và thành phần AWS được ủy quyền mới có thể tương tác với data và services. Amazon CloudWatch: Thu thập và giám sát (collects and monitors) metrics, logs, và trạng thái công việc theo lịch trình (scheduled job statuses) từ Lambda và EC2, giúp duy trì độ tin cậy của hệ thống (system reliability) và hiển thị hiệu suất (performance visibility). Amazon SNS: Gửi thông báo hoặc cảnh báo (notifications or alerts) khi batch jobs hoàn tất, thất bại, hoặc gặp lỗi, đảm bảo nhận biết tình trạng vận hành kịp thời (timely operational awareness). Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật End-to-end data flow Auth (Cognito). Trình duyệt (Browser) thực hiện xác thực (authenticate) với Amazon Cognito thông qua Hosted UI hoặc JS SDK. ID token (JWT) được lưu trong bộ nhớ (stored in memory); SDK sẽ tự động đính kèm (attach) header Authorization: Bearer \u0026lt;JWT\u0026gt; cho các API calls. Static web (CloudFront + S3). SPA/assets được host trên S3; CloudFront nằm phía trước với OAC, gzip/brotli, HTTP/2, và WAF managed rules. Trang web sẽ tải một analytics SDK nhỏ gọn có nhiệm vụ thu thập các sự kiện (events) và gửi chúng đến API Gateway (phía dưới). Event ingest (API Gateway). POST /v1/events (HTTP API). CORS được giới hạn (locked) theo site origin; JWT authorizer sẽ xác thực (validate) Cognito token (hoặc API key đối với anonymous flows). Các requests sau đó được chuyển tiếp (forwarded) đến Lambda để xử lý. Security \u0026amp; Ops. IAM được cấu hình theo nguyên tắc least-privilege cho từng component. CloudWatch theo dõi logs, metrics, và alarms liên quan đến API 5xx, Lambda errors, throttles, và Shiny health. SNS sẽ gửi thông báo (notify) khi có alarms hoặc khi DLQ tăng trưởng bất thường (DLQ growth). Processing \u0026amp; storage (Lambda → DynamoDB(datalake) → PostgreSQL on EC2(data warehouse)→ Shiny). Lambda thực hiện xác thực (validate) và làm giàu dữ liệu (enrich) các events, sau đó ghi vào DynamoDB (các bảng session/event). Một ETL job nhỏ chạy trên EC2 sẽ định kỳ (periodically) nén và tổng hợp (compact/aggregate) dữ liệu từ DynamoDB vào curated store (Postgres hoặc DuckDB) trên EC2 data-warehouse node. R Shiny Server (trên EC2) sẽ đọc các curated tables và render dashboards dành cho admins. Data Contracts \u0026amp; Governance Event JSON (ingest)\n{ \u0026#34;event_id\u0026#34;: \u0026#34;uuid-v4\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2025-10-18T12:34:56.789Z\u0026#34;, \u0026#34;event_type\u0026#34;: \u0026#34;view|click|search|add_to_cart|checkout|purchase\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;uuid-v4\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;cognito-sub-or-null\u0026#34;, \u0026#34;anonymous_id\u0026#34;: \u0026#34;stable-anon-id\u0026#34;, \u0026#34;page_url\u0026#34;: \u0026#34;https://site/p/123\u0026#34;, \u0026#34;referrer\u0026#34;: \u0026#34;https://google.com\u0026#34;, \u0026#34;device\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;mobile|desktop|tablet\u0026#34; }, \u0026#34;geo\u0026#34;: { \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;city\u0026#34;: null }, \u0026#34;ecom\u0026#34;: { \u0026#34;product_id\u0026#34;: \u0026#34;sku-123\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;Shoes\u0026#34;, \u0026#34;currency\u0026#34;: \u0026#34;USD\u0026#34;, \u0026#34;price\u0026#34;: 79.99, \u0026#34;qty\u0026#34;: 1, }, \u0026#34;props\u0026#34;: { \u0026#34;search_query\u0026#34;: \u0026#34;running shoes\u0026#34; }, } PII: không bao giờ gửi name/email/phone; mọi optional identifier (nếu có) sẽ được hash trong Lambda. Behaviour: tạo anonymous_id một lần, duy trì session_id (tự động roll sau 30 phút không hoạt động); gửi dữ liệu bằng navigator.sendBeacon với fetch retry fallback; tùy chọn offline buffer thông qua IndexedDB. S3 raw layout \u0026amp; retention\nBucket: s3://clickstream-raw/ Object format: NDJSON, tùy chọn GZIP. Partitioning: year=YYYY/month=MM/day=DD/hour=HH/ → events-\u0026lt;uuid\u0026gt;.ndjson.gz Optional manifest per batch: bao gồm processed watermark, object list, record counts, và hash. Lifecycle: raw → (30 days Standard/IA) → (365+ days Glacier/Flex). Idempotency: duy trì một compact staging table trong PostgreSQL (hoặc một small S3 key-value manifest) để theo dõi (track) last processed object/batch và ngăn chặn việc tải trùng (prevent double-load). Frontend SDK (Static site on S3 + CloudFront) Instrumentation\nMột JS snippet nhỏ được tải trên toàn bộ website (site-wide) với thuộc tính defer. Đoạn mã này tạo anonymous_id một lần và lưu session_id trong localStorage; session sẽ tự động roll sau 30 phút không hoạt động. Các events được gửi qua navigator.sendBeacon; nếu thất bại, fallback sang fetch với retry \u0026amp; jitter. Auth context\nNếu người dùng đăng nhập bằng Cognito, hãy bao gồm trường user_id = idToken.sub để kích hoạt (enable) các logged-in funnels. Offline durability\nOptional Service Worker queue: khi offline, tạm lưu (buffer) các events trong IndexedDB và gửi lại (flush) khi kết nối được khôi phục (on reconnect). Ingestion API (API Gateway → Lambda) API Gateway (HTTP API)\nRoute: POST /v1/events. JWT authorizer: sử dụng Cognito user pool. Đối với các anonymous pre-login events, dùng API key usage-plan với rate limits nghiêm ngặt (strict rate limits). WAF: sử dụng AWS Managed Core + Bot Control; chặn (block) các non-site origins thông qua strict CORS. Lambda (Node.js or Python)\nValidate: kiểm tra dữ liệu dựa trên JSON Schema (sử dụng ajv/pydantic). Idempotency: kiểm tra event_id gần đây trong bảng DynamoDB nhỏ hoặc in-memory cache có TTL để tránh xử lý trùng lặp. Enrichment: trích xuất date/hour, phân tích UA (User-Agent), và suy luận country từ CloudFront-Viewer-Country (nếu có). Persist: thực hiện PutItem vào bảng events, và UpdateItem để cập nhật sessions.last_seen cùng page_count. Failure path: publish các sự kiện lỗi lên SQS DLQ; gửi alarm qua SNS nếu DLQ depth \u0026gt; 0. Batch Buffer (S3) Purpose: cung cấp bộ đệm (buffer) rẻ tiền, bền vững cho batch analytics. Write pattern: ghi các object nhỏ cho từng request hoặc micro-batches (ví dụ: 1–5 MB mỗi object) với GZIP. Optional compactor có thể gộp thành các file ≥64MB để tăng hiệu quả đọc (efficient reads). Read pattern: ETL Lambda chỉ scan các partition/object mới kể từ last watermark. Schema-on-read: ETL áp dụng schema khi đọc, đồng thời xử lý dữ liệu đến muộn (late-arriving data) bằng cách reprocess một cửa sổ trượt nhỏ (ví dụ: 2 giờ gần nhất) để chỉnh sửa sessions. EC2 “data warehouse” node Purpose: chạy ETL và host curated analytical store mà Shiny sẽ truy vấn. Có hai lựa chọn:\nPostgres trên EC2 (khuyến nghị nếu team thích SQL/window functions) Instance: t3.small / t4g.small; gp3 50–100GB Schema: fact_events, fact_sessions, dim_date, dim_product Security: đặt trong VPC private subnet; truy cập thông qua ALB / SSM Session Manager; tự động snapshot hàng ngày vào S3 ETL (Lambda, batch qua EventBridge cron) Trigger: chạy theo chu kỳ rate(5 minutes) hoặc cron(\u0026hellip;) tùy thuộc vào cost và freshness (mức độ cập nhật dữ liệu). Các bước: liệt kê các S3 objects mới → đọc dữ liệu → validate/dedupe (kiểm tra hợp lệ và loại bỏ trùng lặp) → transform (làm phẳng cấu trúc nested JSON, ép kiểu dữ liệu, thêm ingest_date, session_window_start/end) → upsert vào Postgres bằng COPY vào temp tables rồi merge, hoặc thực hiện batched INSERT \u0026hellip; ON CONFLICT. Networking: Lambda được gắn với VPC private subnets để có thể truy cập EC2 Postgres security group. R Shiny Server on EC2 (admin analytics) Server\nEC2 (t3.small/t4g.small) với các thành phần: R 4.4+, Shiny Server (open-source), Nginx reverse proxy, TLS thông qua ACM/ALB hoặc Let’s Encrypt. IAM instance profile (không dùng static keys). Security group cho phép HTTPS từ office/VPN hoặc Cognito-gated admin site. App (packages)\nCác package R sử dụng: shiny, shinydashboard/bslib, plotly, DT, dplyr, DBI + RPostgres hoặc duckdb, lubridate. Nếu truy vấn DynamoDB trực tiếp cho các small cards, có thể sử dụng paws.dynamodb (tùy chọn). Dashboards\nTraffic \u0026amp; Engagement: DAU/MAU, sessions, avg pages, bounce proxy. Funnels: view → add_to_cart → checkout → purchase với tỷ lệ chuyển đổi từng stage (stage conversion) và drop-off. Product Performance: views, CTR, ATC rate, revenue theo product/category. Acquisition: referrer, campaign, device, country. Reliability: Lambda error rate, DLQ depth, ETL lag, data freshness. Caching\nQuery results được cache trong quá trình xử lý (in-process) thông qua reactive values hoặc materialized bởi ETL; các cache keys được tạo dựa trên date range và filters. Security baseline IAM\nIngest Lambda: quyền s3:PutObject tới raw bucket (giới hạn theo prefix), s3:ListBucket trên các prefix cần thiết. ETL Lambda: quyền s3:GetObject/ListBucket trên các raw prefixes; có quyền lấy secrets từ SSM Parameter Store; không có quyền truy cập rộng vào S3. EC2 roles: chỉ read/write tới DB/volumes riêng của nó; tùy chọn read S3 cho backups. Shiny EC2: không ghi vào S3 raw; chỉ read-only tới Postgres khi cần. Network\nĐặt EC2 trong private subnets; truy cập công khai qua ALB (HTTPS 443). Lambda thực hiện ETL được join vào VPC để kết nối tới Postgres; Security Group (SG) áp dụng least-privilege (chỉ mở Postgres port từ ETL SG). Không mở rộng 0.0.0.0/0 tới các DB ports. Data\nMã hóa: EBS bằng KMS, S3 server-side encryption, RDS/PG TLS, secrets lưu trong SSM Parameter Store. Dữ liệu nhạy cảm: không có PII trong events; retention: raw S3 90–365 ngày (lifecycle), curated Postgres theo chính sách kinh doanh. Observability \u0026amp; alerting CloudWatch metrics/alarms\nTheo dõi: API Gateway 5xx/latency, Lambda errors/throttles, DLQ depth, DynamoDB throttles, ETL job exit code/lag, Shiny health check. SNS topics: gửi email/SMS/Slack webhook cho on-call team. Structured logs: JSON logs từ Lambda \u0026amp; ETL (bao gồm request_id, event_type, status, ms, error_code). Watermark tracking: custom metric “DW Freshness (minutes since last successful upsert)”.\nCost Controls (stay near Free/low tier) HTTP API được sử dụng (chi phí thấp hơn), Lambda memory tối thiểu (256–512MB), nén requests. Batch thay vì realtime: dùng S3 làm buffer để loại bỏ chi phí ghi/đọc DynamoDB. S3 lifecycle: Standard → Standard-IA/Intelligent-Tiering → Glacier cho dữ liệu raw cũ; bật GZIP để giảm chi phí lưu trữ và truyền tải. Điều chỉnh cadence ETL (ví dụ: 15–60 phút) và chỉ xử lý các object mới; gộp các file nhỏ thành file lớn để giảm read I/O. Single small EC2 cho Shiny + DW ban đầu; sau đó scale vertically hoặc tách riêng khi cần. AWS Budgets với SNS alerts cho chi phí thực tế và dự báo. Deliverables Analytics SDK (TypeScript): hỗ trợ sessionization, beacon, và optional offline queue. API/Lambda (ingest): xử lý validation, enrichment, idempotency hints, và DLQ. S3 raw bucket spec: prefixing/partitioning, compression, lifecycle, kèm optional compactor. ETL Lambda (batch): kết hợp với EventBridge cron, watermarking, và upsert strategy vào PostgreSQL PostgreSQL schema: fact_events, fact_sessions, các dims, cùng indexes và vacuum/maintenance plan. R Shiny dashboard app: gồm 5 modules, triển khai với Nginx/ALB TLS setup. Runbook: bao gồm alarms, on-call, backups, disaster recovery, freshness SLO, và cost guardrails. 5. Lộ trình \u0026amp; Mốc triển khai Dự án theo tiến độ Tháng 1 – Học tập \u0026amp; Chuẩn bị Nghiên cứu một loạt các AWS services bao gồm compute, storage, analytics, và security. Hiểu các khái niệm chính về kiến trúc đám mây (cloud architecture), data pipelines, và serverless computing. Tổ chức các cuộc họp nhóm để đồng bộ mục tiêu dự án và phân công nhiệm vụ.\nTháng 2 – Thiết kế kiến trúc \u0026amp; Prototyping Thiết kế kiến trúc tổng thể của dự án và xác định luồng dữ liệu giữa các thành phần. Thiết lập các AWS resources ban đầu như S3, Lambda, API Gateway, EventBridge, và EC2. Thử nghiệm với các công cụ mã nguồn mở để trực quan hóa và báo cáo. Kiểm tra sample code và xác thực pipeline thu thập và xử lý dữ liệu.\nTháng 3 – Triển khai \u0026amp; Kiểm thử Triển khai toàn bộ kiến trúc dựa trên thiết kế đã được phê duyệt. Tích hợp tất cả các dịch vụ AWS và đảm bảo độ tin cậy của hệ thống. Thực hiện kiểm thử hiệu năng và chức năng. Hoàn thiện tài liệu và chuẩn bị dự án cho buổi trình bày.\n6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng AWS Services\nAmazon Cognito (User Pools): 0.10 USD/tháng(1 monthly active user (MAU), 1 MAU đăng nhập qua SAML hoặc OIDC federation)\nAmazon S3\nS3 Standard: 0.17 USD/tháng (6 GB, 1,000 PUT requests, 1,000 GET requests, 6 GB Data returned, 6 GB Data scanned) Data Transfer: 0.00 USD/tháng (Outbound 6 TB, Inbound 6 TB) Amazon CloudFront (United States): 0.64 USD/tháng(6 GB Data transfer out to internet, 6 GB Data transfer out to origin, 10,000 HTTPS requests)\nAmazon API Gateway (HTTP APIs): 0.01 USD/tháng(10,000 HTTP API requests units)\nAmazon Lambda (Service settings): 0.00 USD/tháng(1,000,000 requests, 512 MB memory)\nAmazon CloudWatch (APIs): 0.03 USD/tháng(100 metrics GetMetricData, 1,000 metrics GetMetricWidgetImage, 1,000 API requests)\nAmazon SNS (Service settings): 0.02 USD/tháng(1,000,000 requests, 100,000 HTTP/HTTPS Notifications, 1,000 EMAIL/EMAIL-JSON Notifications, 100,000,000 QS Notifications, 100,000,000 Lambda deliveries, 100,000 Kinesis Data Firehose notifications)\nAmazon EC2 (EC2 specifications): 1.68 USD/tháng(1 instance, 730 Compute Savings Plans)\nAmazon EventBridge: 0.00 USD/tháng(1,000,000 events (AWS management events - EventBridge Event Bus Ingestion))\nTổng cộng: 2.65 USD/tháng, 31.8 USD/12 tháng\n7. Đánh giá rủi ro Risk Likelihood Impact Mitigation Strategy Chi phí cao vượt quá ngân sách ước tính Medium High Theo dõi chặt chẽ và tính toán tất cả các chi phí tiềm năng trên AWS. Giới hạn việc sử dụng các dịch vụ AWS có chi phí cao và thay thế bằng các giải pháp đơn giản, tiết kiệm chi phí nhưng cung cấp chức năng tương tự. Các vấn đề tiềm ẩn trong việc truyền dữ liệu hoặc tích hợp dịch vụ giữa các thành phần AWS Medium Medium Thực hiện step-by-step validation trước khi triển khai chính thức. Thử nghiệm sớm, sử dụng các managed AWS services, và liên tục giám sát hiệu suất thông qua Amazon CloudWatch. Rủi ro trong thu thập hoặc xử lý dữ liệu (ví dụ: tương tác người dùng quá mức, mạng không ổn định, thiếu hoặc trùng lặp sự kiện) High Medium Áp dụng data validation, temporary buffering, và schema enforcement để đảm bảo tính nhất quán. Sử dụng structured logging và alarms để phát hiện và xử lý lỗi khi ingest dữ liệu. Người dùng ít hoặc không sử dụng analytics dashboard Low High Tổ chức các buổi internal training và tận dụng các communication channels hiện có để nâng cao nhận thức. Khuyến khích việc sử dụng bằng cách trình bày các practical benefits và actionable insights của hệ thống. 8. Kết quả kỳ vọng Hiểu Hành Vi và Hành Trình Khách Hàng Hệ thống ghi lại toàn bộ hành trình khách hàng — bao gồm các trang mà người dùng truy cập, sản phẩm mà họ xem, thời gian họ ở lại, và điểm họ rời khỏi trang web.\nBằng cách phân tích session duration, bounce rate, và navigation paths, doanh nghiệp có thể đánh giá mức độ tương tác của người dùng và trải nghiệm tổng thể.\nĐiều này cung cấp nền tảng dữ liệu đáng tin cậy để cải thiện giao diện website, tối ưu bố cục trang, và nâng cao overall customer satisfaction.\nXác Định Sản Phẩm Phổ Biến và Xu Hướng Người Tiêu Dùng Dựa trên clickstream data được thu thập và xử lý trên AWS, hệ thống xác định các sản phẩm được xem nhiều nhất và mua nhiều nhất.\nCác sản phẩm ít được chú ý cũng được theo dõi, cho phép doanh nghiệp đánh giá hiệu quả của product listings, điều chỉnh giá cả hoặc hình ảnh sản phẩm, và lập kế hoạch tồn kho hiệu quả hơn.\nHơn nữa, hệ thống hỗ trợ phát hiện shopping trends theo khoảng thời gian, khu vực, hoặc loại thiết bị — giúp đưa ra quyết định kinh doanh kịp thời và dựa trên dữ liệu.\nTối Ưu Chiến Lược Marketing và Bán Hàng Dữ liệu hành vi của khách hàng được transform (chuyển đổi) thành business insights (thông tin kinh doanh chuyên sâu) và được trình bày thông qua R Shiny dashboards.\nVới các kết quả phân tích này, doanh nghiệp có thể:\nXác định chính xác target customer segments cho các nỗ lực marketing Tùy chỉnh các chiến dịch quảng cáo và khuyến mãi cho các nhóm sản phẩm hoặc đối tượng khách hàng cụ thể Đánh giá hiệu quả của các sáng kiến marketing thông qua các chỉ số tương tác và chuyển đổi có thể đo lường Kết quả là, marketing and sales strategies trở nên dựa trên bằng chứng và chính xác hơn, hỗ trợ ra quyết định tốt hơn và cải thiện hiệu suất kinh doanh.\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Mở rộng deployment pipeline với Amazon ECS blue/green deployments và lifecycle hooks. Bài blog giới thiệu cách mở rộng quy trình triển khai ứng dụng với Amazon ECS blue/green deployments kết hợp lifecycle hooks. Blue/green cho phép chuyển đổi lưu lượng an toàn giữa hai môi trường, trong khi lifecycle hooks (các hàm Lambda chèn vào từng giai đoạn triển khai) giúp thêm logic tuỳ chỉnh như kiểm thử, xác thực, hay phê duyệt thủ công. Nhờ đó, doanh nghiệp có thể kiểm soát tốt hơn quá trình triển khai, giảm rủi ro và dễ dàng rollback khi gặp sự cố.\nBlog 2 - Tăng tốc việc kiểm thử serverless với tích hợp LocalStack trong VS Code IDE. Bài blog giới thiệu việc tích hợp LocalStack vào AWS Toolkit for VS Code, giúp lập trình viên dễ dàng kiểm thử và gỡ lỗi ứng dụng serverless ngay trên máy local mà không cần triển khai lên AWS thật. Nhờ đó, quá trình phát triển, kiểm thử tích hợp và triển khai ứng dụng serverless trở nên nhanh chóng, thuận tiện và liền mạch hơn ngay trong IDE.\nBlog 3 - Xây dựng kiến trúc backup tập trung cross-Region với AWS Control Tower Bài blog trình bày cách xây dựng kiến trúc sao lưu tập trung đa vùng (cross-Region) bằng cách tích hợp AWS Backup với AWS Control Tower. Theo đó, khi bật tích hợp này, Control Tower sẽ tự động tạo các vault sao lưu trung tâm tại mỗi vùng trong một tài khoản “central backup”, và vault bản địa trong từng tài khoản workload. Với chính sách sao lưu (backup policies), bạn có thể cấu hình sao lưu cục bộ hoặc sao chép chéo vùng, áp dụng nhất quán trên toàn tổ chức — từ đó giảm độ phức tạp vận hành, đảm bảo tuân thủ và tăng khả năng dự phòng dữ liệu.\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/hoangvananh2162004/hoangvananh2162004.github.io.git/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]